import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O æ•¸æ“šæ¡é›†ç«™", layout="wide")
st.title("ğŸ“Š D&O æ™ºèƒ½æ ¸ä¿ - æ•¸æ“šæ¡é›†çµ‚ç«¯")

# è®€å– Secrets (è«‹ç¢ºä¿ .streamlit/secrets.toml æˆ–ç’°å¢ƒè®Šæ•¸å·²è¨­å®š)
# è‹¥åœ¨æœ¬åœ°é‹è¡Œï¼Œä¹Ÿå¯ç›´æ¥å°‡ URL/KEY å¡«å…¥ä¸‹æ–¹å­—ä¸² (ä½†ä¸å»ºè­° commit åˆ° github)
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. è¼”åŠ©å‡½æ•¸ï¼šæ—¥æœŸè½‰æ°‘åœ‹å­£åˆ¥ ---
def date_to_roc_quarter(date_obj):
    """å°‡ datetime ç‰©ä»¶è½‰ç‚º '114å¹´ Q3' æ ¼å¼"""
    year_roc = date_obj.year - 1911
    quarter = (date_obj.month - 1) // 3 + 1
    return f"{year_roc}å¹´ Q{quarter}"

# --- 3. æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ (yfinance ç‰ˆ) ---
def fetch_and_upload_data(stock_code):
    status_text = st.empty()
    status_text.info(f"ğŸ” æ­£åœ¨é€£ç·š Yahoo Finance æŠ“å– {stock_code}...")
    
    # è™•ç†å°è‚¡ä»£è™Ÿ (åŠ ä¸Š .TW)
    ticker_symbol = f"{stock_code}.TW" if not stock_code.endswith(".TW") else stock_code
    stock = yf.Ticker(ticker_symbol)
    
    try:
        # A. æŠ“å–ä¸‰å¤§å ±è¡¨ (Quarterly)
        # yfinance çš„ quarterly_xxx é€šå¸¸é è¨­å›å‚³è¿‘ 4-5 å­£ï¼Œæˆ‘å€‘ç›¡é‡æŠ“å–
        bs = stock.quarterly_balance_sheet  # è³‡ç”¢è² å‚µè¡¨
        is_ = stock.quarterly_financials    # æç›Šè¡¨
        cf = stock.quarterly_cashflow       # ç¾é‡‘æµé‡è¡¨ (é—œéµ!)

        if bs.empty or is_.empty:
            st.error(f"âŒ æ‰¾ä¸åˆ° {stock_code} çš„è²¡å‹™æ•¸æ“šï¼Œè«‹ç¢ºèªä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚")
            return

        # B. åˆä½µå ±è¡¨ (ä»¥æ—¥æœŸç‚º Index)
        # è½‰ç½®(T)è®“æ—¥æœŸè®Š Indexï¼Œæ–¹ä¾¿ concat
        df_merged = pd.concat([is_.T, bs.T, cf.T], axis=1)
        
        # ç§»é™¤é‡è¤‡æ¬„ä½ (æœ‰äº›é …ç›®åç¨±å¯èƒ½é‡è¤‡)
        df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]
        
        # C. ç¯©é¸èˆ‡æ”¹å (Mapping)
        # å®šç¾©æˆ‘å€‘è¦æŠ“çš„é …ç›® (è‹±æ–‡ -> ä¸­æ–‡)
        # è¨»ï¼šyfinance çš„æ¬„ä½åç¨±å¯èƒ½æœƒéš¨ç‰ˆæœ¬è®Šå‹•ï¼Œé€™è£¡åˆ—å‡ºå¸¸è¦‹åç¨±
        mapping = {
            "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥", # å‚™ç”¨
            "Total Assets": "ç¸½è³‡ç”¢",
            "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ", # ç”¨æ–¼è¨ˆç®—è² å‚µæ¯”
            "Total Liabilities": "ç¸½è² å‚µ", # å‚™ç”¨
            "Current Assets": "æµå‹•è³‡ç”¢",
            "Current Liabilities": "æµå‹•è² å‚µ",
            "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", # ğŸ”¥ é—œéµæ–°å¢
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        }
        
        # æº–å‚™æ‰“åŒ…çš„è³‡æ–™çµæ§‹
        # ç‚ºäº†è¦è®“ API èƒ½ç®—å‡º YoYï¼Œæˆ‘å€‘å˜—è©¦å–æœ€è¿‘ 8 å€‹æ™‚é–“é» (å¦‚æœæœ‰çš„è©±)
        # sort_index(ascending=False) ç¢ºä¿æœ€æ–°çš„åœ¨å‰é¢
        df_merged.index = pd.to_datetime(df_merged.index)
        df_sorted = df_merged.sort_index(ascending=False).head(8) # æŠ“è¿‘ 8 å­£
        
        # å»ºç«‹ç›®æ¨™é …ç›®æ¸…å–®
        target_items = [
            "ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", 
            "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", 
            "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        ]
        
        formatted_data = [] # æº–å‚™å­˜æˆ List[Dict]

        for target_name in target_items:
            row_dict = {"é …ç›®": target_name}
            
            for date_idx in df_sorted.index:
                key_name = date_to_roc_quarter(date_idx) # è½‰æˆ "114å¹´ Q3"
                
                # 1. è² å‚µæ¯”ç‰¹æ®Šè¨ˆç®—
                if target_name == "è² å‚µæ¯”":
                    try:
                        liab = df_sorted.loc[date_idx].get("Total Liabilities Net Minority Interest") or df_sorted.loc[date_idx].get("Total Liabilities")
                        assets = df_sorted.loc[date_idx].get("Total Assets")
                        if liab and assets:
                            val = (liab / assets) * 100
                            row_dict[key_name] = f"{val:.2f}%"
                        else:
                            row_dict[key_name] = "-"
                    except:
                        row_dict[key_name] = "-"
                        
                # 2. å…¶ä»–ä¸€èˆ¬é …ç›®
                else:
                    # æ‰¾å°æ‡‰çš„è‹±æ–‡æ¬„ä½
                    found_val = None
                    for eng_col, ch_col in mapping.items():
                        if ch_col == target_name:
                            if eng_col in df_sorted.columns:
                                val = df_sorted.loc[date_idx, eng_col]
                                # æª¢æŸ¥æ˜¯å¦ç‚º NaN
                                if pd.notna(val):
                                    found_val = val
                                    break
                    
                    if found_val is not None:
                        # å–®ä½æ›ç®—ï¼šé™¤äº† EPS å’Œç™¾åˆ†æ¯”ï¼Œå…¶ä»–è½‰ç‚ºã€Œåƒå…ƒã€
                        if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                            # åŸå§‹æ•¸æ“šé€šå¸¸æ˜¯å…ƒï¼Œé™¤ä»¥ 1000
                            val_thousands = int(found_val / 1000)
                            # æ ¼å¼åŒ–åŠ ä¸Šé€—è™Ÿ
                            row_dict[key_name] = f"{val_thousands:,}"
                        else:
                            # EPS ä¿æŒåŸæ¨£
                            row_dict[key_name] = f"{found_val:.2f}"
                    else:
                        row_dict[key_name] = "-"
            
            formatted_data.append(row_dict)

        # D. ä¸Šå‚³ Supabase
        stock_name = stock.info.get('longName', stock_code) # å˜—è©¦æŠ“ä¸­æ–‡å
        
        payload = {
            "code": stock_code,
            "name": stock_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        
        # Upsert (æœ‰å‰‡æ›´æ–°ï¼Œç„¡å‰‡æ–°å¢)
        data, count = supabase.table("underwriting_cache").upsert(payload).execute()
        
        status_text.success(f"âœ… æˆåŠŸï¼{stock_code} ({stock_name}) æ•¸æ“šå·²åŒæ­¥è‡³ä¸­å°ã€‚")
        st.json(formatted_data) # é¡¯ç¤ºé è¦½

    except Exception as e:
        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        # é¡¯ç¤ºè©³ç´°éŒ¯èª¤ä»¥ä¾¿é™¤éŒ¯
        import traceback
        st.text(traceback.format_exc())

# --- 4. Streamlit UI ä»‹é¢ ---
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### ğŸ“¥ æ•¸æ“šåŒæ­¥ä¸­å¿ƒ")
    stock_input = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ", value="2330", help="ä¾‹å¦‚ 2330, 2881")
    
    if st.button("ğŸš€ åŸ·è¡Œæ¡é›† / æ›´æ–°æ•¸æ“š", type="primary"):
        if stock_input:
            fetch_and_upload_data(stock_input)
        else:
            st.warning("è«‹è¼¸å…¥ä»£è™Ÿ")

    st.markdown("---")
    st.markdown("""
    **åŠŸèƒ½èªªæ˜ï¼š**
    * ä¾†æºï¼šYahoo Finance (å³æ™‚)
    * ç¯„åœï¼šå˜—è©¦æŠ“å–è¿‘ 8 å­£æ•¸æ“š
    * é …ç›®ï¼šåŒ…å«ç¾é‡‘æµã€ç‡Ÿæ”¶ã€è² å‚µæ¯”
    * å–®ä½ï¼šè‡ªå‹•æ›ç®—ç‚ºã€Œåƒå…ƒã€
    """)

with col2:
    st.markdown("### ğŸ’¾ ä¸­å°æ•¸æ“šé è¦½ (Supabase)")
    # ç°¡å–®çš„æŸ¥è©¢åŠŸèƒ½æŸ¥çœ‹ç›®å‰ DB ç‹€æ³
    if st.button("ğŸ”„ é‡æ–°æ•´ç†è³‡æ–™åº«åˆ—è¡¨"):
        try:
            res = supabase.table("underwriting_cache").select("code, name, updated_at").order("updated_at", desc=True).limit(10).execute()
            if res.data:
                df_db = pd.DataFrame(res.data)
                st.dataframe(df_db, use_container_width=True)
            else:
                st.info("ç›®å‰è³‡æ–™åº«ç‚ºç©º")
        except Exception as e:
            st.error(f"è®€å–å¤±æ•—: {e}")
