import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime
import time
import requests
import ssl
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# å¿½ç•¥ SSL è­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O å…¨å°è‚¡æ¡é›†ä¸­å¿ƒ", layout="wide", page_icon="ğŸ“Š")
st.title("ğŸ“Š D&O æ™ºèƒ½æ ¸ä¿ - å…¨å°è‚¡è‡ªå‹•åŒ–æ¡é›†ä¸­å¿ƒ (å«å¹´åº¦å ±è¡¨)")

# è®€å– Supabase è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å– ä¸Šå¸‚/ä¸Šæ«ƒ/èˆˆæ«ƒ ç¸½è¡¨ ---
@st.cache_data(ttl=3600)
def get_all_tw_companies():
    """å¾è­‰äº¤æ‰€æŠ“å–ä¸¦åˆä½µæ¸…å–®"""
    sources = [
        ("ä¸Šå¸‚", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"),
        ("ä¸Šæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"),
        ("èˆˆæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=5")
    ]
    all_dfs = []
    
    progress_text = st.empty()
    try:
        for market_name, url in sources:
            progress_text.text(f"æ­£åœ¨ä¸‹è¼‰ {market_name} æ¸…å–®...")
            response = requests.get(url, verify=False)
            response.encoding = 'cp950'
            dfs = pd.read_html(response.text)
            df = dfs[0]
            
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].notna()]
            df_stock = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains('ã€€')]
            df_stock[['ä»£è™Ÿ', 'åç¨±']] = df_stock['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', expand=True).iloc[:, :2]
            df_stock['å¸‚å ´åˆ¥'] = market_name
            
            target_cols = ['ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ä¸Šå¸‚æ—¥']
            for col in target_cols:
                if col not in df_stock.columns: df_stock[col] = "-"
            
            clean_df = df_stock[target_cols]
            clean_df = clean_df[clean_df['ä»£è™Ÿ'].str.match(r'^\d{4}$')]
            all_dfs.append(clean_df)
            
        progress_text.empty()
        if all_dfs:
            return pd.concat(all_dfs, ignore_index=True)
        return pd.DataFrame()
    except Exception as e:
        st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
        return pd.DataFrame()

# --- 3. è¼”åŠ©å‡½æ•¸ ---
def date_to_roc_quarter(date_obj):
    """å°‡æ—¥æœŸè½‰ç‚ºæ°‘åœ‹å­£åˆ¥ (ä¾‹å¦‚: 114å¹´ Q1)"""
    year_roc = date_obj.year - 1911
    quarter = (date_obj.month - 1) // 3 + 1
    return f"{year_roc}å¹´ Q{quarter}"

def date_to_roc_year(date_obj):
    """å°‡æ—¥æœŸè½‰ç‚ºæ°‘åœ‹å¹´åº¦ (ä¾‹å¦‚: 112å¹´)"""
    year_roc = date_obj.year - 1911
    return f"{year_roc}å¹´"

# --- 4. æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ (ä¿®å¾©ç‰ˆï¼šæŠ“å–å¹´åº¦+å­£åº¦) ---
def fetch_and_upload_data(stock_code, stock_name_tw=None, market_type="ä¸Šå¸‚"):
    """
    æŠ“å–å­£åº¦èˆ‡å¹´åº¦å ±è¡¨ä¸¦åˆä½µ
    """
    suffix = ".TWO" if market_type in ["ä¸Šæ«ƒ", "èˆˆæ«ƒ"] else ".TW"
    ticker_symbol = f"{stock_code}{suffix}"
    
    stock = yf.Ticker(ticker_symbol)
    
    try:
        # ==========================================
        # æ­¥é©Ÿ A: æŠ“å–ã€Œå­£åº¦ã€å ±è¡¨ (Quarterly)
        # ==========================================
        q_bs = stock.quarterly_balance_sheet
        q_is = stock.quarterly_financials
        q_cf = stock.quarterly_cashflow 
        
        if q_bs.empty or q_is.empty:
            return False, f"ç„¡è²¡å‹™æ•¸æ“š ({ticker_symbol})"

        # åˆä½µå­£åº¦å ±è¡¨
        df_q = pd.concat([q_is.T, q_bs.T, q_cf.T], axis=1)
        df_q = df_q.loc[:, ~df_q.columns.duplicated()]
        df_q.index = pd.to_datetime(df_q.index)
        # åªå–è¿‘ 12 å­£
        df_q_sorted = df_q.sort_index(ascending=False).head(12)

        # ==========================================
        # æ­¥é©Ÿ B: æŠ“å–ã€Œå¹´åº¦ã€å ±è¡¨ (Annual) - æ–°å¢åŠŸèƒ½ ğŸ”¥
        # ==========================================
        a_bs = stock.balance_sheet
        a_is = stock.financials
        a_cf = stock.cashflow

        df_a_sorted = pd.DataFrame()
        if not a_is.empty:
            df_a = pd.concat([a_is.T, a_bs.T, a_cf.T], axis=1)
            df_a = df_a.loc[:, ~df_a.columns.duplicated()]
            df_a.index = pd.to_datetime(df_a.index)
            # å–è¿‘ 5 å¹´
            df_a_sorted = df_a.sort_index(ascending=False).head(5)

        # ==========================================
        # æ­¥é©Ÿ C: æ•´åˆæ¬„ä½èˆ‡æ•¸æ“š
        # ==========================================
        mapping = {
            "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥", "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Total Assets": "ç¸½è³‡ç”¢",
            "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ", "Total Liabilities": "ç¸½è² å‚µ",
            "Current Assets": "æµå‹•è³‡ç”¢", "Current Liabilities": "æµå‹•è² å‚µ",
            "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
            "Total Cash From Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
            "Cash Flow From Continuing Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        }
        
        target_items = [
            "ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", 
            "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", 
            "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        ]
        
        formatted_data = []

        for target_name in target_items:
            row_dict = {"é …ç›®": target_name}
            
            # --- 1. è™•ç†å­£åº¦æ•¸æ“š (Quarterly) ---
            for date_idx in df_q_sorted.index:
                key_name = date_to_roc_quarter(date_idx) # æ ¼å¼ï¼š114å¹´ Q1
                val = extract_value(df_q_sorted, date_idx, target_name, mapping)
                row_dict[key_name] = val

            # --- 2. è™•ç†å¹´åº¦æ•¸æ“š (Annual) ---
            if not df_a_sorted.empty:
                for date_idx in df_a_sorted.index:
                    key_name = date_to_roc_year(date_idx) # æ ¼å¼ï¼š112å¹´
                    val = extract_value(df_a_sorted, date_idx, target_name, mapping)
                    row_dict[key_name] = val
            
            formatted_data.append(row_dict)

        # ä¸Šå‚³ Supabase
        final_name = stock_name_tw if stock_name_tw else stock.info.get('longName', stock_code)
        payload = {
            "code": stock_code,
            "name": final_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        supabase.table("underwriting_cache").upsert(payload).execute()
        return True, f"æˆåŠŸåŒæ­¥: {final_name} ({suffix})"

    except Exception as e:
        return False, str(e)

# æ•¸å€¼æå–è¼”åŠ©å‡½å¼
def extract_value(df, date_idx, target_name, mapping):
    if target_name == "è² å‚µæ¯”":
        try:
            liab = df.loc[date_idx].get("Total Liabilities Net Minority Interest") or df.loc[date_idx].get("Total Liabilities")
            assets = df.loc[date_idx].get("Total Assets")
            if liab and assets:
                return f"{(liab / assets) * 100:.2f}%"
        except: pass
        return "-"
    else:
        found_val = None
        for eng_col, ch_col in mapping.items():
            if ch_col == target_name and eng_col in df.columns:
                val = df.loc[date_idx, eng_col]
                if pd.notna(val):
                    found_val = val
                    break
        
        if found_val is not None:
            if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                try: return f"{int(found_val / 1000):,}"
                except: return "-"
            else:
                return f"{found_val:.2f}"
    return "-"

# --- 5. UI ä»‹é¢ (ä¿æŒä¸è®Š) ---
with st.sidebar:
    st.header("ğŸ’¾ è³‡æ–™åº«ç‹€æ…‹")
    if st.button("ğŸ”„ åˆ·æ–°è³‡æ–™åº«åˆ—è¡¨"):
        try:
            res = supabase.table("underwriting_cache").select("code, name, updated_at", count="exact").execute()
            st.metric("å·²å»ºæª”å…¬å¸æ•¸", res.count)
            if res.data:
                df_db = pd.DataFrame(res.data)
                df_db['updated_at'] = pd.to_datetime(df_db['updated_at']).dt.strftime('%Y-%m-%d %H:%M')
                st.dataframe(df_db, hide_index=True)
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—: {e}")

tab1, tab2 = st.tabs(["ğŸš€ å…¨å¸‚å ´æ‰¹é‡æ¡é›†", "ğŸ” æ‰‹å‹•æŸ¥è©¢"])

with tab1:
    st.markdown("### ğŸ¢ ä¸Šå¸‚ / ä¸Šæ«ƒ / èˆˆæ«ƒ ç¸½è¡¨")
    col_src1, col_src2 = st.columns(2)
    with col_src1:
        if st.button("ğŸŒ ä¸‹è¼‰å…¨å¸‚å ´æœ€æ–°æ¸…å–®"):
            with st.spinner("ä¸‹è¼‰ä¸­..."):
                df = get_all_tw_companies()
                if not df.empty:
                    st.session_state.twse_df = df
                    st.success(f"æˆåŠŸè¼‰å…¥ {len(df)} å®¶å…¬å¸")
    with col_src2:
        if st.button("ğŸ’¾ è¼‰å…¥ Supabase æ¸…å–®"):
            with st.spinner("è®€å–ä¸­..."):
                try:
                    res = supabase.table("underwriting_cache").select("code, name, updated_at").execute()
                    if res.data:
                        df_db = pd.DataFrame(res.data)
                        df_db = df_db.rename(columns={"code": "ä»£è™Ÿ", "name": "åç¨±"})
                        df_db['ç”¢æ¥­åˆ¥'] = "å·²å»ºæª”"
                        df_db['å¸‚å ´åˆ¥'] = "Supabase"
                        df_db['ä¸Šå¸‚æ—¥'] = df_db['updated_at'].apply(lambda x: str(x)[:10])
                        st.session_state.twse_df = df_db
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(df_db)} ç­†")
                except Exception as e: st.error(f"å¤±æ•—: {e}")

    if 'twse_df' in st.session_state and st.session_state.twse_df is not None:
        df = st.session_state.twse_df
        st.markdown("---")
        c1, c2, c3 = st.columns(3)
        with c1: mkt = st.selectbox("å¸‚å ´", ["å…¨éƒ¨"] + list(df['å¸‚å ´åˆ¥'].unique()))
        with c2: ind = st.selectbox("ç”¢æ¥­", ["å…¨éƒ¨"] + list(df['ç”¢æ¥­åˆ¥'].unique()))
        with c3: txt = st.text_input("æœå°‹", "")
        
        f_df = df.copy()
        if mkt != "å…¨éƒ¨": f_df = f_df[f_df['å¸‚å ´åˆ¥'] == mkt]
        if ind != "å…¨éƒ¨": f_df = f_df[f_df['ç”¢æ¥­åˆ¥'] == ind]
        if txt: f_df = f_df[f_df['ä»£è™Ÿ'].str.contains(txt) | f_df['åç¨±'].str.contains(txt)]
        
        st.write(f"å…± {len(f_df)} ç­†")
        
        # å…¨é¸é‚è¼¯
        if 'editor_key' not in st.session_state: st.session_state.editor_key = 0
        if 'def_sel' not in st.session_state: st.session_state.def_sel = False
        cb1, cb2, _ = st.columns([1,1,6])
        if cb1.button("âœ… å…¨é¸"): 
            st.session_state.def_sel = True
            st.session_state.editor_key += 1
            st.rerun()
        if cb2.button("âŒ å–æ¶ˆ"): 
            st.session_state.def_sel = False
            st.session_state.editor_key += 1
            st.rerun()
            
        f_df['é¸å–'] = st.session_state.def_sel
        valid_cols = [c for c in ['é¸å–', 'ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥'] if c in f_df.columns]
        
        edited_df = st.data_editor(
            f_df[valid_cols], hide_index=True,
            column_config={"é¸å–": st.column_config.CheckboxColumn(required=True)},
            disabled=[c for c in valid_cols if c != 'é¸å–'],
            height=400, key=f"editor_{st.session_state.editor_key}"
        )
        
        sel_rows = edited_df[edited_df['é¸å–'] == True]
        if not sel_rows.empty and st.button("ğŸš€ åŸ·è¡Œæ›´æ–°"):
            p_bar = st.progress(0)
            status = st.empty()
            total = len(sel_rows)
            for i, row in enumerate(sel_rows.itertuples()):
                code = getattr(row, 'ä»£è™Ÿ')
                name = getattr(row, 'åç¨±')
                mkt_type = getattr(row, 'å¸‚å ´åˆ¥', 'ä¸Šå¸‚')
                status.text(f"è™•ç†ä¸­ ({i+1}/{total}): {code}")
                fetch_and_upload_data(code, name, mkt_type)
                p_bar.progress((i+1)/total)
                time.sleep(1)
            status.success("å®Œæˆ")

with tab2:
    st.markdown("### æ‰‹å‹•æŸ¥è©¢")
    s_in = st.text_input("ä»£è™Ÿ", value="2330")
    m_type = st.radio("å¸‚å ´", ["ä¸Šå¸‚", "ä¸Šæ«ƒ/èˆˆæ«ƒ"], horizontal=True)
    if st.button("åŸ·è¡Œå–®ç­†"):
        real_mkt = "ä¸Šå¸‚" if "ä¸Šå¸‚" in m_type else "ä¸Šæ«ƒ"
        suc, msg = fetch_and_upload_data(s_in, market_type=real_mkt)
        if suc: st.success(msg)
        else: st.error(msg)
