import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime, timedelta
import time
import requests
import ssl
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# å¿½ç•¥ SSL è­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O è£œæ¼æ¡é›†å™¨ (V20.0)", layout="wide", page_icon="ğŸ›¡ï¸")
st.title("ğŸ›¡ï¸ D&O æ™ºèƒ½æ ¸ä¿ - ç¼ºæ¼è³‡æ–™è£œè¶³ç³»çµ± (ç‡Ÿæ”¶æ ¸å½ˆç‰ˆ)")

# è®€å– Supabase è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å–å¸‚å ´ç¸½è¡¨ ---
@st.cache_data(ttl=3600)
def get_all_tw_companies():
    sources = [
        ("ä¸Šå¸‚", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"),
        ("ä¸Šæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"),
        ("èˆˆæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=5")
    ]
    all_dfs = []
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7'
    })

    try:
        for market_name, url in sources:
            response = session.get(url, verify=False, timeout=15)
            response.encoding = 'cp950'
            dfs = pd.read_html(response.text)
            df = dfs[0]
            
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].notna()]
            df_stock = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains('ã€€')]
            df_stock[['ä»£è™Ÿ', 'åç¨±']] = df_stock['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', expand=True).iloc[:, :2]
            df_stock['å¸‚å ´åˆ¥'] = market_name
            
            target_cols = ['ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥']
            for col in target_cols:
                if col not in df_stock.columns:
                    df_stock[col] = "-"
            
            clean_df = df_stock[target_cols]
            clean_df = clean_df[clean_df['ä»£è™Ÿ'].str.match(r'^\d{4}$')]
            all_dfs.append(clean_df)
            time.sleep(1)
            
        if all_dfs:
            return pd.concat(all_dfs, ignore_index=True)
        return pd.DataFrame()
    except Exception as e:
        st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
        return pd.DataFrame()

def get_all_db_data():
    try:
        all_data = []
        start = 0
        batch_size = 1000 
        while True:
            response = supabase.table("underwriting_cache").select("code, name, financial_data").range(start, start + batch_size - 1).execute()
            data = response.data
            if not data: break
            all_data.extend(data)
            if len(data) < batch_size: break
            start += batch_size
        return all_data
    except Exception as e:
        st.error(f"è®€å–è³‡æ–™åº«å¤±æ•—: {e}")
        return []

# --- 3. è¼”åŠ©å‡½æ•¸ ---
def date_to_roc_quarter(date_str):
    try:
        if isinstance(date_str, str):
            date_obj = datetime.strptime(date_str, '%Y-%m-%d')
        else:
            date_obj = date_str
        year_roc = date_obj.year - 1911
        quarter = (date_obj.month - 1) // 3 + 1
        return f"{year_roc}å¹´ Q{quarter}"
    except:
        return "æœªçŸ¥å­£åº¦"

def get_quarter_from_date(date_obj):
    """å›å‚³ (å¹´ä»½, å­£åº¦) tuple"""
    return (date_obj.year, (date_obj.month - 1) // 3 + 1)

# --- ğŸ”¥ FinMind æ•‘æ´æŠ•æ‰‹ (V20 ç‡Ÿæ”¶æ ¸å½ˆç‰ˆ) ---
def fetch_finmind_data_history(stock_code):
    try:
        start_date = (datetime.now() - timedelta(days=1095)).strftime('%Y-%m-%d')
        base_url = "https://api.finmindtrade.com/api/v4/data"
        token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNi0wMi0wNiAxNDoxNToxMSIsInVzZXJfaWQiOiJqaW1teTk4NTA0MDIiLCJlbWFpbCI6IjExMDI1NTAyNEBnLm5jY3UuZWR1LnR3IiwiaXAiOiIyMjMuMTM3LjEwMC4xMjgifQ.2ou0rtCaMqV7XXPBh28jGWFJ7_4EQrtr2CdhNQ5YznI"
        headers = {"Authorization": f"Bearer {token}"}

        def get_fm_dataset(dataset_name):
            params = {"dataset": dataset_name, "data_id": stock_code, "start_date": start_date}
            try:
                res = requests.get(base_url, params=params, headers=headers, timeout=5)
                json_data = res.json()
                if json_data.get('msg') == 'success': return json_data.get('data', [])
            except: pass
            return []

        data_income = get_fm_dataset("TaiwanStockFinancialStatements")
        data_balance = get_fm_dataset("TaiwanStockBalanceSheet")
        data_cash = get_fm_dataset("TaiwanStockCashFlowsStatement")
        data_rev = get_fm_dataset("TaiwanStockMonthRevenue")

        if not any([data_income, data_balance, data_cash, data_rev]): return None

        quarter_buckets = {}
        monthly_rev_map = {} # ç”¨ä¾†å­˜æœˆç‡Ÿæ”¶ï¼š {(year, month): value}

        # --- 0. é è™•ç†æœˆç‡Ÿæ”¶ ---
        if data_rev:
            for row in data_rev:
                try:
                    dt = datetime.strptime(row['date'], '%Y-%m-%d')
                    monthly_rev_map[(dt.year, dt.month)] = row['revenue']
                except: pass

        # è¼”åŠ©ï¼šå¾æœˆç‡Ÿæ”¶è¨ˆç®—å­£ç‡Ÿæ”¶
        def calculate_quarterly_rev(year, quarter):
            months = []
            if quarter == 1: months = [1, 2, 3]
            elif quarter == 2: months = [4, 5, 6]
            elif quarter == 3: months = [7, 8, 9]
            elif quarter == 4: months = [10, 11, 12]
            
            total = 0
            count = 0
            for m in months:
                if (year, m) in monthly_rev_map:
                    total += monthly_rev_map[(year, m)]
                    count += 1
            # åªè¦æœ‰æŠ“åˆ°ä»»ä¸€å€‹æœˆçš„è³‡æ–™ï¼Œå°±ç®—æ•¸ (èˆˆæ«ƒæœ‰æ™‚å€™æœƒç¼ºæœˆ)
            if count > 0:
                return total
            return None

        def add_candidate(date_str, category, key, value):
            q_str = date_to_roc_quarter(date_str)
            if q_str not in quarter_buckets:
                quarter_buckets[q_str] = {
                    "EPS_Candidates": {}, "Rev_Candidates": {}, "CF_Candidates": {},
                    "Assets": None, "Liabs": None, "CurAssets": None, "CurLiabs": None,
                    "DateObj": datetime.strptime(date_str, '%Y-%m-%d') # å­˜æ—¥æœŸç‰©ä»¶ä»¥ä¾¿è¨ˆç®—
                }
            
            # æ›´æ–°æ—¥æœŸç‰©ä»¶ï¼Œä¿æŒè©²å­£åº¦æœ€æ–°çš„æ—¥æœŸ
            curr_dt = datetime.strptime(date_str, '%Y-%m-%d')
            if curr_dt > quarter_buckets[q_str]["DateObj"]:
                quarter_buckets[q_str]["DateObj"] = curr_dt

            if category == "EPS": quarter_buckets[q_str]["EPS_Candidates"][key] = value
            elif category == "Rev": quarter_buckets[q_str]["Rev_Candidates"][key] = value
            elif category == "CF": quarter_buckets[q_str]["CF_Candidates"][key] = value
            elif category == "Assets": quarter_buckets[q_str]["Assets"] = value
            elif category == "Liabs": quarter_buckets[q_str]["Liabs"] = value
            elif category == "CurAssets": quarter_buckets[q_str]["CurAssets"] = value
            elif category == "CurLiabs": quarter_buckets[q_str]["CurLiabs"] = value

        # --- A. EPS ---
        if data_income:
            eps_keys = ['EPS', 'BasicEarningsPerShare', 'EarningsPerShare', 'NetIncomePerShare']
            for row in data_income:
                if row['type'] in eps_keys:
                    add_candidate(row['date'], "EPS", row['type'], row['value'])

        # --- B. ç‡Ÿæ”¶ (å­£å ±) ---
        if data_income:
            rev_keys = [
                'OperatingRevenue', 'Revenue', 'TotalOperatingRevenue', 
                'NetRevenue', 'SalesRevenue', 'NetSales',
                'InterestIncome', 'InsuranceRevenue', 'GrossProfit'
            ]
            for row in data_income:
                # é—œéµå­—å‘½ä¸­
                if row['type'] in rev_keys:
                    add_candidate(row['date'], "Rev", row['type'], row['value'])
                # æ¨¡ç³Šå‘½ä¸­ (åŒ…å« Revenue ä¸”éç‡Ÿæ¥­å¤–)
                elif "Revenue" in row['type'] and "Non" not in row['type']:
                    add_candidate(row['date'], "Rev", row['type'], row['value'])
        
        # --- C. è³‡ç”¢è² å‚µ ---
        if data_balance:
            for row in data_balance:
                t, d, v = row['type'], row['date'], row['value']
                if t in ['TotalAssets', 'Assets']: add_candidate(d, "Assets", t, v)
                if t in ['TotalLiabilities', 'Liabilities']: add_candidate(d, "Liabs", t, v)
                if t in ['CurrentAssets', 'TotalCurrentAssets', 'AssetsCurrent']: add_candidate(d, "CurAssets", t, v)
                if t in ['CurrentLiabilities', 'TotalCurrentLiabilities', 'LiabilitiesCurrent']: add_candidate(d, "CurLiabs", t, v)

        # --- D. ç¾é‡‘æµ ---
        if data_cash:
            cf_keys = ['NetCashInflowFromOperatingActivities', 'CashFlowsFromOperatingActivities', 'CashFlowFromOperatingActivities']
            for row in data_cash:
                if row['type'] in cf_keys:
                    add_candidate(row['date'], "CF", row['type'], row['value'])

        # --- E. å„ªå…ˆç´šè§£æ (Resolution) ---
        sorted_quarters = sorted(quarter_buckets.keys(), reverse=True)[:6]
        final_struct = {
            "ç‡Ÿæ¥­æ”¶å…¥": {}, "æ¯è‚¡ç›ˆé¤˜(EPS)": {}, "ç¸½è³‡ç”¢": {}, "ç¸½è² å‚µ": {},
            "æµå‹•è³‡ç”¢": {}, "æµå‹•è² å‚µ": {}, "è² å‚µæ¯”": {}, "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ": {}
        }

        REV_PRIORITY = ['OperatingRevenue', 'Revenue', 'TotalOperatingRevenue', 'NetRevenue', 'SalesRevenue', 'NetSales', 'InterestIncome', 'GrossProfit']
        EPS_PRIORITY = ['EPS', 'BasicEarningsPerShare', 'EarningsPerShare']
        CF_PRIORITY = ['NetCashInflowFromOperatingActivities', 'CashFlowsFromOperatingActivities', 'CashFlowFromOperatingActivities']

        for q in sorted_quarters:
            bucket = quarter_buckets[q]

            # 1. EPS
            for p_key in EPS_PRIORITY:
                if p_key in bucket["EPS_Candidates"]:
                    final_struct["æ¯è‚¡ç›ˆé¤˜(EPS)"][q] = f"{bucket['EPS_Candidates'][p_key]:.2f}"
                    break
            
            # 2. ç‡Ÿæ”¶ (æ ¸å½ˆç´šé‚è¼¯ï¼šå­£å ± -> æœˆå ±åŠ ç¸½)
            found_rev = False
            # (1) å…ˆæŸ¥å­£å ± VIP åå–®
            for p_key in REV_PRIORITY:
                if p_key in bucket["Rev_Candidates"]:
                    final_struct["ç‡Ÿæ¥­æ”¶å…¥"][q] = f"{int(bucket['Rev_Candidates'][p_key]/1000):,}"
                    found_rev = True
                    break
            
            # (2) è‹¥å­£å ±æ²’ä¸­ï¼Œå•Ÿå‹•ã€Œæœˆç‡Ÿæ”¶åŠ ç¸½ã€
            if not found_rev:
                # å–å¾—è©²å­£åº¦çš„å¹´ä»½èˆ‡å­£åˆ¥
                d_obj = bucket["DateObj"]
                y, q_num = get_quarter_from_date(d_obj)
                
                # è¨ˆç®—
                calc_rev = calculate_quarterly_rev(y, q_num)
                if calc_rev is not None:
                    final_struct["ç‡Ÿæ¥­æ”¶å…¥"][q] = f"{int(calc_rev/1000):,} (æœˆåŠ ç¸½)"
                    found_rev = True

            # 3. ç¾é‡‘æµ
            for p_key in CF_PRIORITY:
                if p_key in bucket["CF_Candidates"]:
                    final_struct["ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"][q] = f"{int(bucket['CF_Candidates'][p_key]/1000):,}"
                    break
            
            # 4. å…¶ä»–
            if bucket["Assets"]: 
                final_struct["ç¸½è³‡ç”¢"][q] = f"{int(bucket['Assets']/1000):,}"
                if bucket["Liabs"]:
                    final_struct["ç¸½è² å‚µ"][q] = f"{int(bucket['Liabs']/1000):,}"
                    if bucket["Assets"] > 0:
                        final_struct["è² å‚µæ¯”"][q] = f"{(bucket['Liabs'] / bucket['Assets']) * 100:.2f}%"
            if bucket["CurAssets"]: final_struct["æµå‹•è³‡ç”¢"][q] = f"{int(bucket['CurAssets']/1000):,}"
            if bucket["CurLiabs"]: final_struct["æµå‹•è² å‚µ"][q] = f"{int(bucket['CurLiabs']/1000):,}"

        # æœˆç‡Ÿæ”¶
        if data_rev:
            rows = sorted(data_rev, key=lambda x: x['date'], reverse=True)
            for row in rows[:8]:
                m_key = f"{row['date'][:7]} (æœˆ)"
                final_struct["ç‡Ÿæ¥­æ”¶å…¥"][m_key] = f"{int(row['revenue']/1000):,}"

        formatted_list = []
        order = ["ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "ç¸½è² å‚µ", "è² å‚µæ¯”", "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"]
        for item_name in order:
            if final_struct[item_name]:
                row_dict = {"é …ç›®": item_name}
                row_dict.update(final_struct[item_name])
                formatted_list.append(row_dict)
            else:
                formatted_list.append({"é …ç›®": item_name})
        
        formatted_list.append({"é …ç›®": "è³‡æ–™ä¾†æº", "èªªæ˜": "FinMind (èˆˆæ«ƒå‚™æ´)"})
        return formatted_list

    except Exception as e:
        print(f"Error: {e}")
        return None

# --- 4. æ ¸å¿ƒçˆ¬èŸ² ---
def fetch_and_upload_data(stock_code, stock_name_tw=None, market_type="ä¸Šå¸‚", force_finmind=False):
    suffix = ".TWO" if market_type in ["ä¸Šæ«ƒ", "èˆˆæ«ƒ"] else ".TW"
    ticker_symbol = f"{stock_code}{suffix}"
    stock = yf.Ticker(ticker_symbol)
    
    formatted_data = []
    source_used = "yfinance"

    try:
        if force_finmind:
             fm_data_list = fetch_finmind_data_history(stock_code)
             if fm_data_list:
                 source_used = "FinMind (å¼·åˆ¶ä¿®è£œ)"
                 formatted_data = fm_data_list
             else:
                 return False, f"âŒ FinMind æš«ç„¡è³‡æ–™: {stock_name_tw}"
        else:
            q_bs = stock.quarterly_balance_sheet
            q_is = stock.quarterly_financials
            
            if q_bs.empty or q_is.empty:
                fm_data_list = fetch_finmind_data_history(stock_code)
                if fm_data_list:
                    source_used = "FinMind"
                    formatted_data = fm_data_list
                else:
                    return False, f"âŒ ç„¡æ•¸æ“šè·³é: {stock_name_tw}"
            else:
                q_cf = stock.quarterly_cashflow 
                df_q = pd.concat([q_is.T, q_bs.T, q_cf.T], axis=1)
                df_q = df_q.loc[:, ~df_q.columns.duplicated()]
                df_q.index = pd.to_datetime(df_q.index)
                df_q_sorted = df_q.sort_index(ascending=False).head(12)

                a_bs = stock.balance_sheet
                a_is = stock.financials
                a_cf = stock.cashflow
                df_a_sorted = pd.DataFrame()
                if not a_is.empty:
                    df_a = pd.concat([a_is.T, a_bs.T, a_cf.T], axis=1)
                    df_a = df_a.loc[:, ~df_a.columns.duplicated()]
                    df_a.index = pd.to_datetime(df_a.index)
                    df_a_sorted = df_a.sort_index(ascending=False).head(5)

                mapping = {
                    "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥", "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
                    "Total Assets": "ç¸½è³‡ç”¢",
                    "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ", "Total Liabilities": "ç¸½è² å‚µ",
                    "Current Assets": "æµå‹•è³‡ç”¢", "Current Liabilities": "æµå‹•è² å‚µ",
                    "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
                    "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
                    "Total Cash From Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
                    "Cash Flow From Continuing Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
                }
                
                target_items = ["ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"]

                for target_name in target_items:
                    row_dict = {"é …ç›®": target_name}
                    for date_idx in df_q_sorted.index:
                        key_name = date_to_roc_quarter(date_idx)
                        val = extract_value(df_q_sorted, date_idx, target_name, mapping)
                        row_dict[key_name] = val
                    
                    if not df_a_sorted.empty:
                        for date_idx in df_a_sorted.index:
                            key_name = date_to_roc_year(date_idx)
                            val = extract_value(df_a_sorted, date_idx, target_name, mapping)
                            row_dict[key_name] = val
                    
                    formatted_data.append(row_dict)

        final_name = stock_name_tw if stock_name_tw else stock.info.get('longName', stock_code)
        payload = {
            "code": stock_code,
            "name": final_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        supabase.table("underwriting_cache").upsert(payload).execute()
        return True, f"âœ… æˆåŠŸ: {final_name} ({source_used})"

    except Exception as e:
        return False, str(e)

def extract_value(df, date_idx, target_name, mapping):
    if target_name == "è² å‚µæ¯”":
        try:
            liab = df.loc[date_idx].get("Total Liabilities Net Minority Interest") or df.loc[date_idx].get("Total Liabilities")
            assets = df.loc[date_idx].get("Total Assets")
            if liab and assets: return f"{(liab / assets) * 100:.2f}%"
        except: pass
        return "-"
    else:
        found_val = None
        for eng_col, ch_col in mapping.items():
            if ch_col == target_name and eng_col in df.columns:
                val = df.loc[date_idx, eng_col]
                if pd.notna(val): found_val = val; break
        
        if found_val is not None:
            if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                try: return f"{int(found_val / 1000):,}"
                except: return "-"
            else: return f"{found_val:.2f}"
    return "-"

# --- 5. UI ä»‹é¢ ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” è£œæ¼ç›£æ§", "ğŸš‘ è³‡æ–™ä¿®è£œ (Fix)", "ğŸ•µï¸ æ·±åº¦è¨ºæ–·", "ğŸ“ å–®ç­†æ‰‹å‹•"])

with tab1:
    st.markdown("### ğŸ“‰ ç¼ºæ¼åå–®è£œè¶³")
    if st.button("ğŸ”„ 1. æƒæç¼ºæ¼", type="primary"):
        with st.spinner("æƒæä¸­..."):
            full_df = get_all_tw_companies()
            db_data = get_all_db_data()
            db_codes = {str(item['code']) for item in db_data}
            
            if not full_df.empty:
                full_df['code_str'] = full_df['ä»£è™Ÿ'].astype(str).str.strip()
                missing_df = full_df[~full_df['code_str'].isin(db_codes)].copy()
                st.session_state.missing_df = missing_df
                st.session_state.db_count = len(db_codes)
                st.success(f"ç™¼ç¾ {len(missing_df)} å®¶ç¼ºæ¼ã€‚")

    if 'missing_df' in st.session_state and not st.session_state.missing_df.empty:
        m_df = st.session_state.missing_df
        st.dataframe(m_df.head(50))
        if st.button(f"ğŸš€ è£œè¶³ {len(m_df)} å®¶"):
            p = st.progress(0); stt = st.empty()
            cnt = 0
            for i, row in enumerate(m_df.itertuples()):
                stt.text(f"è™•ç†: {row.ä»£è™Ÿ} {row.åç¨±}")
                ok, _ = fetch_and_upload_data(row.ä»£è™Ÿ, row.åç¨±, row.å¸‚å ´åˆ¥)
                if ok: cnt += 1
                p.progress((i+1)/len(m_df))
            st.success(f"è£œè¶³ {cnt} å®¶")

with tab2:
    st.markdown("### ğŸš‘ èˆˆæ«ƒè³‡æ–™ä¿®è£œä¸­å¿ƒ (V20.0 ç‡Ÿæ”¶æ ¸å½ˆ)")
    if st.button("ğŸ” 1. æƒæéœ€ä¿®è£œåå–®"):
        with st.spinner("åˆ†æè³‡æ–™åº«å“è³ªä¸­..."):
            all_data = get_all_db_data()
            repair_list = []
            for item in all_data:
                code = str(item['code'])
                name = item['name']
                fdata = item['financial_data']
                is_finmind = False
                has_rev = False
                eps_count = 0
                if isinstance(fdata, list):
                    for row in fdata:
                        if "èªªæ˜" in row and "FinMind" in row.get("èªªæ˜", ""): is_finmind = True
                        if row.get("é …ç›®") == "ç‡Ÿæ¥­æ”¶å…¥":
                            if len([k for k in row.keys() if k != "é …ç›®"]) > 0: has_rev = True
                        if row.get("é …ç›®") == "æ¯è‚¡ç›ˆé¤˜(EPS)":
                            eps_count = len([k for k in row.keys() if k != "é …ç›®"])
                if is_finmind and (not has_rev or eps_count <= 1):
                    repair_list.append({"code": code, "name": name})
            
            if repair_list:
                st.session_state.repair_df = pd.DataFrame(repair_list)
                st.warning(f"ç™¼ç¾ {len(repair_list)} å®¶ã€‚")
                st.dataframe(st.session_state.repair_df)
            else: st.success("è³‡æ–™åº«å“è³ªè‰¯å¥½ã€‚")

    if 'repair_df' in st.session_state:
        r_df = st.session_state.repair_df
        if st.button(f"ğŸ› ï¸ 2. å¼·åˆ¶ä¿®è£œ {len(r_df)} å®¶"):
            p_bar = st.progress(0)
            status = st.empty()
            fixed_cnt = 0
            total = len(r_df)
            for i, row in enumerate(r_df.itertuples()):
                code = getattr(row, 'code')
                name = getattr(row, 'name')
                status.text(f"ä¿®è£œ: {code} {name} ...")
                ok, msg = fetch_and_upload_data(code, name, "èˆˆæ«ƒ", force_finmind=True)
                if ok: fixed_cnt += 1
                p_bar.progress((i+1)/total)
                time.sleep(1.0)
            st.success(f"å®Œæˆï¼æ›´æ–° {fixed_cnt} å®¶ã€‚")

with tab3:
    st.markdown("### ğŸ•µï¸ æ·±åº¦è¨ºæ–· (Debug)")
    debug_code = st.text_input("ä»£è™Ÿ", value="4546")
    if st.button("è¨ºæ–·æ­¤å…¬å¸"):
        with st.spinner("è¨ºæ–·ä¸­..."):
            token = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNi0wMi0wNiAxNDoxNToxMSIsInVzZXJfaWQiOiJqaW1teTk4NTA0MDIiLCJlbWFpbCI6IjExMDI1NTAyNEBnLm5jY3UuZWR1LnR3IiwiaXAiOiIyMjMuMTM3LjEwMC4xMjgifQ.2ou0rtCaMqV7XXPBh28jGWFJ7_4EQrtr2CdhNQ5YznI"
            headers = {"Authorization": f"Bearer {token}"}
            base_url = "https://api.finmindtrade.com/api/v4/data"
            start_date = (datetime.now() - timedelta(days=900)).strftime('%Y-%m-%d')
            
            res = requests.get(base_url, params={"dataset": "TaiwanStockBalanceSheet", "data_id": debug_code, "start_date": start_date}, headers=headers)
            if res.json().get('msg') == 'success':
                df = pd.DataFrame(res.json().get('data', []))
                if not df.empty:
                    st.write("#### è³‡ç”¢è² å‚µè¡¨æ‰€æœ‰æ¬„ä½ (Keys):")
                    st.code(list(df['type'].unique()))
                else: st.warning("è³‡ç”¢è² å‚µè¡¨ç„¡è³‡æ–™")

            res = requests.get(base_url, params={"dataset": "TaiwanStockFinancialStatements", "data_id": debug_code, "start_date": start_date}, headers=headers)
            if res.json().get('msg') == 'success':
                df = pd.DataFrame(res.json().get('data', []))
                if not df.empty:
                    st.write("#### æç›Šè¡¨æ‰€æœ‰æ¬„ä½ (Keys):")
                    st.code(list(df['type'].unique()))
            
            res = requests.get(base_url, params={"dataset": "TaiwanStockCashFlowsStatement", "data_id": debug_code, "start_date": start_date}, headers=headers)
            if res.json().get('msg') == 'success':
                df = pd.DataFrame(res.json().get('data', []))
                if not df.empty:
                    st.write("#### ç¾é‡‘æµé‡è¡¨æ‰€æœ‰æ¬„ä½ (Keys):")
                    st.code(list(df['type'].unique()))

with tab4:
    st.markdown("### ğŸ“ æ‰‹å‹•å–®ç­†æŸ¥è©¢")
    s_in = st.text_input("è¼¸å…¥ä»£è™Ÿ", value="1269", key="manual_in")
    m_type = st.radio("å¸‚å ´", ["ä¸Šå¸‚", "ä¸Šæ«ƒ/èˆˆæ«ƒ"], horizontal=True, key="manual_mkt")
    if st.button("åŸ·è¡Œ", key="manual_btn"):
        with st.spinner(f"æŠ“å– {s_in}..."):
            ok, msg = fetch_and_upload_data(s_in, market_type=("ä¸Šå¸‚" if "ä¸Šå¸‚" in m_type else "ä¸Šæ«ƒ"))
            if ok: st.success(msg)
            else: st.error(msg)
