import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime
import time
import requests
import ssl
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# å¿½ç•¥ SSL è­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O å…¨å°è‚¡æ¡é›†ä¸­å¿ƒ", layout="wide", page_icon="ğŸ“Š")
st.title("ğŸ“Š D&O æ™ºèƒ½æ ¸ä¿ - å…¨å°è‚¡è‡ªå‹•åŒ–æ¡é›†ä¸­å¿ƒ")

# è®€å– Supabase è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å– TWSE ä¸Šå¸‚ç¸½è¡¨ (ä¿®å¾© SSL ç‰ˆ) ---
@st.cache_data(ttl=3600)
def get_twse_listed_companies():
    """å¾è­‰äº¤æ‰€ç¶²ç«™æŠ“å–æ‰€æœ‰ä¸Šå¸‚å…¬å¸æ¸…å–® (å·²ä¿®å¾© SSL éŒ¯èª¤)"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        # ğŸ”¥ é—œéµä¿®æ­£ï¼šä½¿ç”¨ requests ä¸¦é—œé–‰æ†‘è­‰é©—è­‰
        response = requests.get(url, verify=False)
        response.encoding = 'cp950' # è­‰äº¤æ‰€ç·¨ç¢¼é€šå¸¸ç‚º Big5/cp950
        
        # ä½¿ç”¨ pandas è®€å– HTML å­—ä¸²
        dfs = pd.read_html(response.text)
        df = dfs[0]
        
        # è³‡æ–™æ¸…ç†
        df.columns = df.iloc[0]
        df = df.iloc[1:]
        
        # ç¯©é¸å‡ºæœ‰ä»£è™Ÿçš„åˆ—
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].notna()]
        
        # åªè¦è‚¡ç¥¨ (æœ‰å…¨å½¢ç©ºç™½åˆ†éš”çš„é€šå¸¸æ˜¯è‚¡ç¥¨)
        df_stock = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains('ã€€')]
        
        # æ‹†åˆ† ä»£è™Ÿ èˆ‡ åç¨±
        df_stock[['ä»£è™Ÿ', 'åç¨±']] = df_stock['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', expand=True).iloc[:, :2]
        
        # åªä¿ç•™éœ€è¦çš„æ¬„ä½
        clean_df = df_stock[['ä»£è™Ÿ', 'åç¨±', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥', 'å¸‚å ´åˆ¥']]
        
        # éæ¿¾ä»£è™Ÿï¼šåªç•™ 4 ç¢¼æ•¸å­— (æ’é™¤æ¬Šè­‰ã€ETN ç­‰)
        clean_df = clean_df[clean_df['ä»£è™Ÿ'].str.match(r'^\d{4}$')]
        
        return clean_df
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å–è­‰äº¤æ‰€æ¸…å–®: {e}")
        return pd.DataFrame()

# --- 3. è¼”åŠ©å‡½æ•¸ï¼šæ—¥æœŸè½‰æ°‘åœ‹å­£åˆ¥ ---
def date_to_roc_quarter(date_obj):
    year_roc = date_obj.year - 1911
    quarter = (date_obj.month - 1) // 3 + 1
    return f"{year_roc}å¹´ Q{quarter}"

# --- 4. æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ (yfinance + Cash Flow) ---
def fetch_and_upload_data(stock_code, stock_name_tw=None):
    """
    æŠ“å–å–®ä¸€è‚¡ç¥¨æ•¸æ“šä¸¦ä¸Šå‚³
    """
    ticker_symbol = f"{stock_code}.TW"
    stock = yf.Ticker(ticker_symbol)
    
    try:
        # A. æŠ“å–ä¸‰å¤§å ±è¡¨ (Quarterly)
        bs = stock.quarterly_balance_sheet
        is_ = stock.quarterly_financials
        cf = stock.quarterly_cashflow # ğŸ”¥ å‹™å¿…æŠ“å–ç¾é‡‘æµ
        
        if bs.empty or is_.empty:
            return False, "ç„¡è²¡å‹™æ•¸æ“š (å¯èƒ½ç„¡æ¬Šé™æˆ–ä»£è™ŸéŒ¯èª¤)"

        # B. åˆä½µå ±è¡¨
        df_merged = pd.concat([is_.T, bs.T, cf.T], axis=1)
        # ç§»é™¤é‡è¤‡æ¬„ä½
        df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]
        df_merged.index = pd.to_datetime(df_merged.index)
        
        # C. æŠ“å–è¿‘ 12 å­£ (3å¹´) ä»¥ç¢ºä¿æœ‰ YoY å’Œ 2023/2024 è³‡æ–™
        df_sorted = df_merged.sort_index(ascending=False).head(12)
        
        # D. æ¬„ä½å°ç…§ Mapping (Yahoo Finance -> ä¸­æ–‡)
        mapping = {
            "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Total Assets": "ç¸½è³‡ç”¢",
            "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ",
            "Total Liabilities": "ç¸½è² å‚µ",
            "Current Assets": "æµå‹•è³‡ç”¢",
            "Current Liabilities": "æµå‹•è² å‚µ",
            "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", # ğŸ”¥ é—œéµæ¬„ä½
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        }
        
        target_items = [
            "ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", 
            "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", 
            "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        ]
        
        formatted_data = []

        for target_name in target_items:
            row_dict = {"é …ç›®": target_name}
            for date_idx in df_sorted.index:
                key_name = date_to_roc_quarter(date_idx)
                
                # 1. è² å‚µæ¯”ç‰¹æ®Šè¨ˆç®—
                if target_name == "è² å‚µæ¯”":
                    try:
                        liab = df_sorted.loc[date_idx].get("Total Liabilities Net Minority Interest") or df_sorted.loc[date_idx].get("Total Liabilities")
                        assets = df_sorted.loc[date_idx].get("Total Assets")
                        if liab and assets:
                            val = (liab / assets) * 100
                            row_dict[key_name] = f"{val:.2f}%"
                        else:
                            row_dict[key_name] = "-"
                    except:
                        row_dict[key_name] = "-"
                
                # 2. å…¶ä»–ä¸€èˆ¬é …ç›®
                else:
                    found_val = None
                    # å˜—è©¦å„ç¨®å¯èƒ½çš„è‹±æ–‡æ¬„ä½åç¨±
                    for eng_col, ch_col in mapping.items():
                        if ch_col == target_name:
                            if eng_col in df_sorted.columns:
                                val = df_sorted.loc[date_idx, eng_col]
                                if pd.notna(val):
                                    found_val = val
                                    break
                    
                    if found_val is not None:
                        # å–®ä½æ›ç®—ï¼šé™¤äº† EPSï¼Œå…¶ä»–è½‰ç‚ºã€Œåƒå…ƒã€
                        if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                            row_dict[key_name] = f"{int(found_val / 1000):,}"
                        else:
                            row_dict[key_name] = f"{found_val:.2f}"
                    else:
                        row_dict[key_name] = "-"
            
            formatted_data.append(row_dict)

        # E. ä¸Šå‚³ Supabase
        final_name = stock_name_tw if stock_name_tw else stock.info.get('longName', stock_code)

        payload = {
            "code": stock_code,
            "name": final_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        
        supabase.table("underwriting_cache").upsert(payload).execute()
        return True, f"æˆåŠŸåŒæ­¥: {final_name}"

    except Exception as e:
        return False, str(e)

# --- 5. Streamlit UI ä»‹é¢ ---
# å´é‚Šæ¬„ï¼šè³‡æ–™åº«ç‹€æ…‹
with st.sidebar:
    st.header("ğŸ’¾ è³‡æ–™åº«ç‹€æ…‹")
    if st.button("ğŸ”„ åˆ·æ–°è³‡æ–™åº«åˆ—è¡¨"):
        try:
            res = supabase.table("underwriting_cache").select("code, name, updated_at", count="exact").execute()
            st.metric("å·²å»ºæª”å…¬å¸æ•¸", res.count)
            if res.data:
                df_db = pd.DataFrame(res.data)
                # ç°¡å–®æ ¼å¼åŒ–æ™‚é–“
                df_db['updated_at'] = pd.to_datetime(df_db['updated_at']).dt.strftime('%Y-%m-%d %H:%M')
                st.dataframe(df_db, hide_index=True)
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—: {e}")

# ä¸»ç•«é¢ Tab
tab1, tab2 = st.tabs(["ğŸš€ ä¸Šå¸‚å…¬å¸ç¸½è¡¨ (æ‰¹é‡)", "ğŸ” æ‰‹å‹•å–®ç­†æŸ¥è©¢"])

# --- Tab 1: æ‰¹é‡ç®¡ç†æ¨¡å¼ (æ–°å¢å…¨é¸åŠŸèƒ½) ---
with tab1:
    st.markdown("### ğŸ¢ æ‰¹é‡æ¡é›†ç®¡ç†")
    
    col_src1, col_src2 = st.columns(2)
    
    # ä¾†æº A: è­‰äº¤æ‰€çˆ¬èŸ² (å·²ä¿®å¾© SSL)
    with col_src1:
        if st.button("ğŸŒ ä¸‹è¼‰ TWSE æœ€æ–°ç¸½è¡¨ (ä¾†æºï¼šè­‰äº¤æ‰€)"):
            with st.spinner("æ­£åœ¨é€£ç·šè­‰äº¤æ‰€ (å·²å¼·åˆ¶ç•¥é SSL é©—è­‰)..."):
                df = get_twse_listed_companies()
                if not df.empty:
                    st.session_state.twse_df = df
                    st.success(f"æˆåŠŸè¼‰å…¥ {len(df)} å®¶ä¸Šå¸‚å…¬å¸ï¼")

    # ä¾†æº B: Supabase ç¾æœ‰æ¸…å–®
    with col_src2:
        if st.button("ğŸ’¾ è¼‰å…¥ Supabase ç¾æœ‰æ¸…å–® (ä¾†æºï¼šè³‡æ–™åº«)"):
            with st.spinner("æ­£åœ¨è®€å–è³‡æ–™åº«..."):
                try:
                    res = supabase.table("underwriting_cache").select("code, name, updated_at").execute()
                    if res.data:
                        df_db = pd.DataFrame(res.data)
                        df_db = df_db.rename(columns={"code": "ä»£è™Ÿ", "name": "åç¨±"})
                        df_db['ç”¢æ¥­åˆ¥'] = "å·²å»ºæª”"
                        df_db['ä¸Šå¸‚æ—¥'] = df_db['updated_at'].apply(lambda x: str(x)[:10])
                        df_db['å¸‚å ´åˆ¥'] = "Supabase"
                        
                        st.session_state.twse_df = df_db
                        st.success(f"æˆåŠŸè¼‰å…¥è³‡æ–™åº«å…§ {len(df_db)} å®¶å…¬å¸ï¼")
                    else:
                        st.warning("è³‡æ–™åº«ç›®å‰ç‚ºç©º")
                except Exception as e:
                    st.error(f"è®€å–å¤±æ•—: {e}")

    # é¡¯ç¤ºèˆ‡æ“ä½œå€
    if 'twse_df' in st.session_state and st.session_state.twse_df is not None:
        df = st.session_state.twse_df
        
        st.markdown("---")
        # 1. ç¯©é¸å™¨
        col_filter1, col_filter2 = st.columns(2)
        with col_filter1:
            all_industries = ["å…¨éƒ¨"] + list(df['ç”¢æ¥­åˆ¥'].unique())
            selected_industry = st.selectbox("ğŸ“‚ ç¯©é¸ç”¢æ¥­åˆ¥", all_industries)
        
        with col_filter2:
            search_keyword = st.text_input("ğŸ” æœå°‹å…¬å¸åç¨±/ä»£è™Ÿ", "")

        # å¥—ç”¨ç¯©é¸
        filtered_df = df.copy()
        if selected_industry != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df['ç”¢æ¥­åˆ¥'] == selected_industry]
        if search_keyword:
            filtered_df = filtered_df[filtered_df['ä»£è™Ÿ'].str.contains(search_keyword) | filtered_df['åç¨±'].str.contains(search_keyword)]

        # 2. é¡¯ç¤ºè¡¨æ ¼ (å«å…¨é¸åŠŸèƒ½)
        st.write(f"é¡¯ç¤º {len(filtered_df)} ç­†è³‡æ–™ (è«‹å‹¾é¸è¦æ›´æ–°çš„å…¬å¸):")
        
        # --- å…¨é¸/å–æ¶ˆå…¨é¸ æŒ‰éˆ•å€ ---
        col_btn1, col_btn2, col_space = st.columns([1, 1, 6])
        
        # åˆå§‹åŒ– Session State ä¾†æ§åˆ¶è¡¨æ ¼åˆ·æ–°
        if 'editor_key' not in st.session_state:
            st.session_state.editor_key = 0
        if 'default_selection' not in st.session_state:
            st.session_state.default_selection = False

        # æŒ‰éˆ•é‚è¼¯ï¼šé»æ“Šå¾Œæ›´æ”¹é è¨­ç‹€æ…‹ä¸¦åˆ·æ–° key
        if col_btn1.button("âœ… å…¨é¸"):
            st.session_state.default_selection = True
            st.session_state.editor_key += 1 # å¼·åˆ¶åˆ·æ–°è¡¨æ ¼
            st.rerun()
            
        if col_btn2.button("âŒ å–æ¶ˆå…¨é¸"):
            st.session_state.default_selection = False
            st.session_state.editor_key += 1 # å¼·åˆ¶åˆ·æ–°è¡¨æ ¼
            st.rerun()

        # è¨­å®šé¸å–æ¬„ä½çš„é è¨­å€¼
        filtered_df['é¸å–'] = st.session_state.default_selection
        
        cols = ['é¸å–'] + [c for c in filtered_df.columns if c != 'é¸å–']
        
        # é¡¯ç¤º Data Editor (åŠ å…¥ key åƒæ•¸ä»¥æ”¯æ´åˆ·æ–°)
        edited_df = st.data_editor(
            filtered_df[cols], 
            hide_index=True, 
            column_config={"é¸å–": st.column_config.CheckboxColumn(required=True)},
            disabled=["ä»£è™Ÿ", "åç¨±", "ç”¢æ¥­åˆ¥", "ä¸Šå¸‚æ—¥", "å¸‚å ´åˆ¥"],
            height=400,
            key=f"editor_{st.session_state.editor_key}" # å‹•æ…‹ Key
        )

        # 3. æ‰¹é‡åŸ·è¡ŒæŒ‰éˆ•
        selected_rows = edited_df[edited_df['é¸å–'] == True]
        
        if not selected_rows.empty:
            st.warning(f"âš ï¸ å³å°‡æ›´æ–° {len(selected_rows)} å®¶å…¬å¸çš„è²¡å‹™æ•¸æ“šã€‚å¤§é‡æ›´æ–°éœ€è€—æ™‚è¼ƒä¹…ï¼Œè«‹å‹¿é—œé–‰è¦–çª—ã€‚")
            
            if st.button("ğŸš€ é–‹å§‹æ‰¹é‡æ›´æ–° (Batch Update)", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                log_area = st.expander("è©³ç´°åŸ·è¡Œç´€éŒ„", expanded=True)
                
                total = len(selected_rows)
                success_count = 0
                
                for i, row in enumerate(selected_rows.itertuples()):
                    code = row.ä»£è™Ÿ
                    name = row.åç¨±
                    
                    status_text.text(f"â³ ({i+1}/{total}) æ­£åœ¨è™•ç†: {code} {name} ...")
                    
                    success, msg = fetch_and_upload_data(code, name)
                    
                    if success:
                        success_count += 1
                        log_area.write(f"âœ… {code} {name}: æˆåŠŸ")
                    else:
                        log_area.write(f"âŒ {code} {name}: {msg}")
                    
                    progress_bar.progress((i + 1) / total)
                    time.sleep(1.5) # æš«åœ 1.5 ç§’é¿å…è¢« Yahoo å°é–
                
                status_text.success(f"ğŸ‰ ä»»å‹™å®Œæˆï¼æˆåŠŸæ›´æ–° {success_count}/{total} å®¶å…¬å¸ã€‚")

# --- Tab 2: å–®ç­†æ¨¡å¼ ---
with tab2:
    st.markdown("### ğŸ“ æ‰‹å‹•è¼¸å…¥ä»£è™Ÿ")
    stock_input = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ", value="2330", help="ä¾‹å¦‚ 2330")
    if st.button("åŸ·è¡Œå–®ç­†æ¡é›†", type="primary"):
        if stock_input:
            with st.spinner(f"æ­£åœ¨æŠ“å– {stock_input} ..."):
                success, msg = fetch_and_upload_data(stock_input)
                if success:
                    st.success(msg)
                else:
                    st.error(msg)
