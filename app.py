import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime
import time
import requests
import ssl
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# å¿½ç•¥ SSL è­¦å‘Š (é¿å…çˆ¬èŸ²æ™‚å› ç‚ºæ†‘è­‰å•é¡Œå ±éŒ¯)
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O å…¨å°è‚¡æ¡é›†ä¸­å¿ƒ", layout="wide", page_icon="ğŸ“Š")
st.title("ğŸ“Š D&O æ™ºèƒ½æ ¸ä¿ - å…¨å°è‚¡è‡ªå‹•åŒ–æ¡é›†ä¸­å¿ƒ (å« EPS è‡ªå‹•è£œç®—)")

# è®€å– Supabase è¨­å®š (å„ªå…ˆè®€å–ç’°å¢ƒè®Šæ•¸ï¼Œè‹¥ç„¡å‰‡è®€å– Streamlit Secrets)
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å– ä¸Šå¸‚/ä¸Šæ«ƒ/èˆˆæ«ƒ ç¸½è¡¨ ---
@st.cache_data(ttl=3600)
def get_all_tw_companies():
    """å¾è­‰äº¤æ‰€æŠ“å–ä¸¦åˆä½µæ¸…å–®"""
    sources = [
        ("ä¸Šå¸‚", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"),
        ("ä¸Šæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"),
        ("èˆˆæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=5")
    ]
    all_dfs = []
    
    progress_text = st.empty()
    try:
        for market_name, url in sources:
            progress_text.text(f"æ­£åœ¨ä¸‹è¼‰ {market_name} æ¸…å–®...")
            response = requests.get(url, verify=False)
            response.encoding = 'cp950'
            dfs = pd.read_html(response.text)
            df = dfs[0]
            
            # è³‡æ–™æ¸…ç†
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].notna()]
            
            # åªè¦è‚¡ç¥¨
            df_stock = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains('ã€€')]
            
            # æ‹†åˆ† ä»£è™Ÿ èˆ‡ åç¨±
            df_stock[['ä»£è™Ÿ', 'åç¨±']] = df_stock['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', expand=True).iloc[:, :2]
            df_stock['å¸‚å ´åˆ¥'] = market_name
            
            # é˜²å‘†ï¼šç¢ºä¿æ¬„ä½å­˜åœ¨
            target_cols = ['ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥']
            for col in target_cols:
                if col not in df_stock.columns:
                    df_stock[col] = "-"
            
            clean_df = df_stock[target_cols]
            clean_df = clean_df[clean_df['ä»£è™Ÿ'].str.match(r'^\d{4}$')]
            all_dfs.append(clean_df)
            
        progress_text.empty()
        if all_dfs:
            return pd.concat(all_dfs, ignore_index=True)
        return pd.DataFrame()
    except Exception as e:
        st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
        return pd.DataFrame()

# --- 3. è¼”åŠ©å‡½æ•¸ ---
def date_to_roc_quarter(date_obj):
    """å°‡æ—¥æœŸè½‰ç‚ºæ°‘åœ‹å­£åˆ¥ (ä¾‹å¦‚: 114å¹´ Q1)"""
    year_roc = date_obj.year - 1911
    quarter = (date_obj.month - 1) // 3 + 1
    return f"{year_roc}å¹´ Q{quarter}"

def date_to_roc_year(date_obj):
    """å°‡æ—¥æœŸè½‰ç‚ºæ°‘åœ‹å¹´åº¦ (ä¾‹å¦‚: 112å¹´)"""
    year_roc = date_obj.year - 1911
    return f"{year_roc}å¹´"

# --- ğŸ”¥ å¼·å¥ç‰ˆ Smart EPS è¨ˆç®—å™¨ ---
def get_smart_eps_dict(stock):
    """
    å¼·å¥ç‰ˆ EPS è¨ˆç®—å™¨ï¼šä¸ä¾è³´å›ºå®šæ—¥æœŸï¼Œè€Œæ˜¯æƒæè©²å¹´åº¦æ‰€æœ‰å­£åº¦è³‡æ–™ã€‚
    ä¿®å¾©äº†å› ç‚ºæ—¥æœŸæ²’å°ä¸Šå°è‡´ Q1 è¢«æ¼ç®—ï¼Œé€²è€Œè®“ Q4 ç®—éŒ¯çš„å•é¡Œã€‚
    """
    smart_dict = {}
    try:
        # 1. å–å¾—æ•¸æ“š (å®¹éŒ¯è™•ç†)
        # æ³¨æ„ï¼šYahoo å›å‚³çš„æ˜¯ Seriesï¼ŒIndex æ˜¯ Timestamp
        q_eps = stock.quarterly_financials.loc["Basic EPS"] if "Basic EPS" in stock.quarterly_financials.index else pd.Series(dtype=float)
        a_eps = stock.financials.loc["Basic EPS"] if "Basic EPS" in stock.financials.index else pd.Series(dtype=float)
        
        # 2. éæ­·æ¯ä¸€å€‹ã€Œå¹´åº¦è²¡å ±ã€ (ä¾‹å¦‚ 2024, 2023...)
        for year_date in a_eps.index:
            target_year = year_date.year  # ä¾‹å¦‚ 2024
            year_total = float(a_eps[year_date]) # å¼·åˆ¶è½‰ float
            
            # 3. æ‰¾å‡ºè©²å¹´åº¦çš„æ‰€æœ‰ã€Œå­£å ±ã€
            # ä¸è«–æ—¥æœŸæ˜¯ 3/30 é‚„æ˜¯ 3/31ï¼Œåªè¦å¹´ä»½å°å°±æŠ“å‡ºä¾†
            if not q_eps.empty:
                quarters_in_year = q_eps[q_eps.index.year == target_year].sort_index()
            else:
                quarters_in_year = pd.Series(dtype=float)
            
            # ç”¨ä¾†ç´¯åŠ å·²çŸ¥çš„å­£åº¦æ•¸å€¼
            known_quarters_sum = 0.0
            
            # 4. è™•ç†æ¯ä¸€å­£ (å¡«å…¥å·²çŸ¥æ•¸æ“šåˆ°å­—å…¸)
            for q_date, q_val in quarters_in_year.items():
                val = float(q_val)
                roc_q = date_to_roc_quarter(q_date) # è½‰æˆ "113å¹´ Q1"
                
                # å­˜å…¥å­—å…¸
                smart_dict[roc_q] = f"{val:.2f}"
                
                # å¦‚æœé€™ä¸æ˜¯ Q4 (é€šå¸¸ Q4 æ˜¯ 10, 11, 12æœˆ)ï¼Œå°±åŠ å…¥ç´¯åŠ 
                # Yahoo å­£å ±æ—¥æœŸé€šå¸¸æ˜¯æœˆåº•ï¼š3/31, 6/30, 9/30, 12/31
                if q_date.month < 10:
                    known_quarters_sum += val
            
            # 5. ğŸ”¥ é—œéµä¿®æ­£ï¼šQ4 è£œæ´é‹ç®— ğŸ”¥
            # æˆ‘å€‘çš„ç›®æ¨™ key
            q4_key = f"{target_year - 1911}å¹´ Q4"
            
            # æª¢æŸ¥è¦å‰‡ï¼š
            # A. å¦‚æœå­—å…¸è£¡é‚„æ²’æœ‰ Q4 (ä»£è¡¨ Yahoo æ²’çµ¦å–®å­£è³‡æ–™)
            # B. æˆ–è€…å­—å…¸è£¡çš„ Q4 æ˜¯ 0 (æœ‰æ™‚å€™ Yahoo æœƒçµ¦ 0)ï¼Œä½†å¹´åº¦ç¸½å’Œæ˜é¡¯æœ‰å€¼
            is_q4_missing = q4_key not in smart_dict
            is_q4_zero_but_annual_exists = (smart_dict.get(q4_key) == "0.00" or smart_dict.get(q4_key) == "0") and (abs(year_total) > 0.05)
            
            if is_q4_missing or is_q4_zero_but_annual_exists:
                # åªæœ‰ç•¶æˆ‘å€‘è‡³å°‘æŠ“åˆ°äº†å‰å¹¾å­£çš„è³‡æ–™ (é¿å…æ•´å¹´éƒ½æ²’è³‡æ–™äº‚ç®—)
                if not quarters_in_year.empty:
                    # æ•¸å­¸å…¬å¼ï¼šQ4 = å¹´åº¦ç¸½å’Œ - (Q1+Q2+Q3)
                    calculated_q4 = year_total - known_quarters_sum
                    
                    # å¯«å…¥å­—å…¸
                    smart_dict[q4_key] = f"{calculated_q4:.2f}"
                    # print(f"ğŸ’¡ [è‡ªå‹•ä¿®è£œ] {target_year} Q4: {year_total} - {known_quarters_sum} = {calculated_q4:.2f}")

    except Exception as e:
        print(f"Smart EPS Error: {e}")
        return {}
    
    return smart_dict

# --- 4. æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ (å«å¹´åº¦+å­£åº¦+EPSè£œç®—) ---
def fetch_and_upload_data(stock_code, stock_name_tw=None, market_type="ä¸Šå¸‚"):
    """
    æŠ“å–å­£åº¦èˆ‡å¹´åº¦å ±è¡¨ä¸¦åˆä½µ
    """
    suffix = ".TWO" if market_type in ["ä¸Šæ«ƒ", "èˆˆæ«ƒ"] else ".TW"
    ticker_symbol = f"{stock_code}{suffix}"
    
    stock = yf.Ticker(ticker_symbol)
    
    try:
        # ğŸ”¥ æ­¥é©Ÿ 0: å…ˆç®—å‡º Smart EPS å­—å…¸ (è£œæ´ç”¨)
        smart_eps_lookup = get_smart_eps_dict(stock)

        # ==========================================
        # æ­¥é©Ÿ A: æŠ“å–ã€Œå­£åº¦ã€å ±è¡¨ (Quarterly)
        # ==========================================
        q_bs = stock.quarterly_balance_sheet
        q_is = stock.quarterly_financials
        q_cf = stock.quarterly_cashflow 
        
        if q_bs.empty or q_is.empty:
            return False, f"ç„¡è²¡å‹™æ•¸æ“š ({ticker_symbol})"

        # åˆä½µå­£åº¦å ±è¡¨
        df_q = pd.concat([q_is.T, q_bs.T, q_cf.T], axis=1)
        df_q = df_q.loc[:, ~df_q.columns.duplicated()]
        df_q.index = pd.to_datetime(df_q.index)
        # åªå–è¿‘ 12 å­£
        df_q_sorted = df_q.sort_index(ascending=False).head(12)

        # ==========================================
        # æ­¥é©Ÿ B: æŠ“å–ã€Œå¹´åº¦ã€å ±è¡¨ (Annual)
        # ==========================================
        a_bs = stock.balance_sheet
        a_is = stock.financials
        a_cf = stock.cashflow

        df_a_sorted = pd.DataFrame()
        if not a_is.empty:
            df_a = pd.concat([a_is.T, a_bs.T, a_cf.T], axis=1)
            df_a = df_a.loc[:, ~df_a.columns.duplicated()]
            df_a.index = pd.to_datetime(df_a.index)
            # å–è¿‘ 5 å¹´
            df_a_sorted = df_a.sort_index(ascending=False).head(5)

        # ==========================================
        # æ­¥é©Ÿ C: æ•´åˆæ¬„ä½èˆ‡æ•¸æ“š
        # ==========================================
        mapping = {
            "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥", "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Total Assets": "ç¸½è³‡ç”¢",
            "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ", "Total Liabilities": "ç¸½è² å‚µ",
            "Current Assets": "æµå‹•è³‡ç”¢", "Current Liabilities": "æµå‹•è² å‚µ",
            "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
            "Total Cash From Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
            "Cash Flow From Continuing Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        }
        
        target_items = [
            "ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", 
            "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", 
            "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        ]
        
        formatted_data = []

        for target_name in target_items:
            row_dict = {"é …ç›®": target_name}
            
            # --- 1. è™•ç†å­£åº¦æ•¸æ“š (Quarterly) ---
            for date_idx in df_q_sorted.index:
                key_name = date_to_roc_quarter(date_idx) # æ ¼å¼ï¼š114å¹´ Q1
                
                # ğŸ”¥ é—œéµï¼šå¦‚æœæ˜¯ EPSï¼Œå„ªå…ˆæŸ¥è¡¨ Smart Dictionary
                if target_name == "æ¯è‚¡ç›ˆé¤˜(EPS)" and key_name in smart_eps_lookup:
                    row_dict[key_name] = smart_eps_lookup[key_name]
                else:
                    # å¦å‰‡èµ°åŸæœ¬çš„æŠ“å–é‚è¼¯
                    val = extract_value(df_q_sorted, date_idx, target_name, mapping)
                    row_dict[key_name] = val
            
            # å¦‚æœæ˜¯ EPSï¼Œé‚„è¦æª¢æŸ¥æœ‰æ²’æœ‰ "è£œç®—å‡ºä¾†çš„ Q4" (é€™äº›å¯èƒ½ä¸åœ¨ df_q_sorted çš„æ—¥æœŸè£¡)
            if target_name == "æ¯è‚¡ç›ˆé¤˜(EPS)":
                for k, v in smart_eps_lookup.items():
                    if "Q4" in k and k not in row_dict:
                        row_dict[k] = v

            # --- 2. è™•ç†å¹´åº¦æ•¸æ“š (Annual) ---
            if not df_a_sorted.empty:
                for date_idx in df_a_sorted.index:
                    key_name = date_to_roc_year(date_idx) # æ ¼å¼ï¼š112å¹´
                    val = extract_value(df_a_sorted, date_idx, target_name, mapping)
                    row_dict[key_name] = val
            
            formatted_data.append(row_dict)

        # ä¸Šå‚³ Supabase
        final_name = stock_name_tw if stock_name_tw else stock.info.get('longName', stock_code)
        payload = {
            "code": stock_code,
            "name": final_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        supabase.table("underwriting_cache").upsert(payload).execute()
        return True, f"æˆåŠŸåŒæ­¥: {final_name} ({suffix})"

    except Exception as e:
        return False, str(e)

# æ•¸å€¼æå–è¼”åŠ©å‡½å¼
def extract_value(df, date_idx, target_name, mapping):
    if target_name == "è² å‚µæ¯”":
        try:
            liab = df.loc[date_idx].get("Total Liabilities Net Minority Interest") or df.loc[date_idx].get("Total Liabilities")
            assets = df.loc[date_idx].get("Total Assets")
            if liab and assets:
                return f"{(liab / assets) * 100:.2f}%"
        except: pass
        return "-"
    else:
        found_val = None
        for eng_col, ch_col in mapping.items():
            if ch_col == target_name and eng_col in df.columns:
                val = df.loc[date_idx, eng_col]
                if pd.notna(val):
                    found_val = val
                    break
        
        if found_val is not None:
            if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                try: return f"{int(found_val / 1000):,}"
                except: return "-"
            else:
                return f"{found_val:.2f}"
    return "-"

# --- 5. UI ä»‹é¢ ---
with st.sidebar:
    st.header("ğŸ’¾ è³‡æ–™åº«ç‹€æ…‹")
    if st.button("ğŸ”„ åˆ·æ–°è³‡æ–™åº«åˆ—è¡¨"):
        try:
            res = supabase.table("underwriting_cache").select("code, name, updated_at", count="exact").execute()
            st.metric("å·²å»ºæª”å…¬å¸æ•¸", res.count)
            if res.data:
                df_db = pd.DataFrame(res.data)
                df_db['updated_at'] = pd.to_datetime(df_db['updated_at']).dt.strftime('%Y-%m-%d %H:%M')
                st.dataframe(df_db, hide_index=True)
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—: {e}")

tab1, tab2 = st.tabs(["ğŸš€ å…¨å¸‚å ´æ‰¹é‡æ¡é›†", "ğŸ” æ‰‹å‹•æŸ¥è©¢"])

with tab1:
    st.markdown("### ğŸ¢ ä¸Šå¸‚ / ä¸Šæ«ƒ / èˆˆæ«ƒ ç¸½è¡¨")
    col_src1, col_src2 = st.columns(2)
    with col_src1:
        if st.button("ğŸŒ ä¸‹è¼‰å…¨å¸‚å ´æœ€æ–°æ¸…å–®"):
            with st.spinner("ä¸‹è¼‰ä¸­ (å«ä¸Šå¸‚/æ«ƒ/èˆˆæ«ƒ)..."):
                df = get_all_tw_companies()
                if not df.empty:
                    st.session_state.twse_df = df
                    st.success(f"æˆåŠŸè¼‰å…¥ {len(df)} å®¶å…¬å¸")
                else:
                    st.error("æ¸…å–®è¼‰å…¥å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")

    with col_src2:
        if st.button("ğŸ’¾ è¼‰å…¥ Supabase æ¸…å–®"):
            with st.spinner("è®€å–è³‡æ–™åº«..."):
                try:
                    res = supabase.table("underwriting_cache").select("code, name, updated_at").execute()
                    if res.data:
                        df_db = pd.DataFrame(res.data)
                        df_db = df_db.rename(columns={"code": "ä»£è™Ÿ", "name": "åç¨±"})
                        df_db['ç”¢æ¥­åˆ¥'] = "å·²å»ºæª”"
                        df_db['å¸‚å ´åˆ¥'] = "Supabase"
                        df_db['ä¸Šå¸‚æ—¥'] = df_db['updated_at'].apply(lambda x: str(x)[:10])
                        st.session_state.twse_df = df_db
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(df_db)} ç­†")
                except Exception as e: st.error(f"è®€å–å¤±æ•—: {e}")

    if 'twse_df' in st.session_state and st.session_state.twse_df is not None:
        df = st.session_state.twse_df
        st.markdown("---")
        
        # ç¯©é¸å™¨ UI
        c1, c2, c3 = st.columns(3)
        with c1: 
            all_mkts = ["å…¨éƒ¨"] + list(df['å¸‚å ´åˆ¥'].unique())
            mkt = st.selectbox("å¸‚å ´", all_mkts)
            
        with c2: 
            # é˜²å‘†ï¼šç¢ºä¿æœ‰ç”¢æ¥­åˆ¥æ¬„ä½
            if 'ç”¢æ¥­åˆ¥' in df.columns:
                all_inds = ["å…¨éƒ¨"] + list(df['ç”¢æ¥­åˆ¥'].unique())
            else:
                all_inds = ["å…¨éƒ¨"]
            ind = st.selectbox("ç”¢æ¥­", all_inds)
            
        with c3: txt = st.text_input("æœå°‹ (ä»£è™Ÿ/åç¨±)", "")
        
        # ç¯©é¸é‚è¼¯
        f_df = df.copy()
        if mkt != "å…¨éƒ¨": f_df = f_df[f_df['å¸‚å ´åˆ¥'] == mkt]
        if ind != "å…¨éƒ¨" and 'ç”¢æ¥­åˆ¥' in f_df.columns: f_df = f_df[f_df['ç”¢æ¥­åˆ¥'] == ind]
        if txt: f_df = f_df[f_df['ä»£è™Ÿ'].str.contains(txt) | f_df['åç¨±'].str.contains(txt)]
        
        st.write(f"é¡¯ç¤º {len(f_df)} ç­†è³‡æ–™:")
        
        # å…¨é¸é‚è¼¯
        if 'editor_key' not in st.session_state: st.session_state.editor_key = 0
        if 'def_sel' not in st.session_state: st.session_state.def_sel = False
        
        cb1, cb2, _ = st.columns([1,1,6])
        if cb1.button("âœ… å…¨é¸"): 
            st.session_state.def_sel = True
            st.session_state.editor_key += 1
            st.rerun()
        if cb2.button("âŒ å–æ¶ˆ"): 
            st.session_state.def_sel = False
            st.session_state.editor_key += 1
            st.rerun()
            
        f_df['é¸å–'] = st.session_state.def_sel
        
        # ç¢ºä¿é¡¯ç¤ºæ¬„ä½å­˜åœ¨
        display_cols = ['é¸å–', 'ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥']
        valid_cols = [c for c in display_cols if c in f_df.columns]
        
        edited_df = st.data_editor(
            f_df[valid_cols], hide_index=True,
            column_config={"é¸å–": st.column_config.CheckboxColumn(required=True)},
            disabled=[c for c in valid_cols if c != 'é¸å–'],
            height=400, key=f"editor_{st.session_state.editor_key}"
        )
        
        sel_rows = edited_df[edited_df['é¸å–'] == True]
        if not sel_rows.empty:
            st.warning(f"âš ï¸ å³å°‡æ›´æ–° {len(sel_rows)} å®¶å…¬å¸")
            if st.button("ğŸš€ åŸ·è¡Œæ‰¹é‡æ›´æ–°", type="primary"):
                p_bar = st.progress(0)
                status = st.empty()
                total = len(sel_rows)
                for i, row in enumerate(sel_rows.itertuples()):
                    # å®‰å…¨å–å¾—å±¬æ€§ (é¿å… AttributeError)
                    code = getattr(row, 'ä»£è™Ÿ') if hasattr(row, 'ä»£è™Ÿ') else row._2 # å‚™ç”¨
                    name = getattr(row, 'åç¨±') if hasattr(row, 'åç¨±') else row._3
                    mkt_type = getattr(row, 'å¸‚å ´åˆ¥', 'ä¸Šå¸‚') if hasattr(row, 'å¸‚å ´åˆ¥') else "ä¸Šå¸‚"
                    
                    status.text(f"è™•ç†ä¸­ ({i+1}/{total}): {code} {name}")
                    fetch_and_upload_data(code, name, mkt_type)
                    p_bar.progress((i+1)/total)
                    time.sleep(1) # é¿å…å°é–
                status.success("ğŸ‰ æ‰¹é‡æ›´æ–°å®Œæˆï¼")

with tab2:
    st.markdown("### ğŸ“ æ‰‹å‹•å–®ç­†æŸ¥è©¢")
    s_in = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ", value="2330", help="ä¾‹å¦‚ 2330, 8069")
    m_type = st.radio("é¸æ“‡å¸‚å ´", ["ä¸Šå¸‚", "ä¸Šæ«ƒ/èˆˆæ«ƒ"], horizontal=True)
    
    if st.button("åŸ·è¡Œå–®ç­†æ¡é›†", type="primary"):
        if s_in:
            real_mkt = "ä¸Šå¸‚" if "ä¸Šå¸‚" in m_type else "ä¸Šæ«ƒ"
            with st.spinner(f"æ­£åœ¨æŠ“å– {s_in} ({real_mkt})..."):
                suc, msg = fetch_and_upload_data(s_in, market_type=real_mkt)
                if suc: st.success(msg)
                else: st.error(msg)
