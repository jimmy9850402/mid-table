import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime
import time
import requests
import ssl
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# å¿½ç•¥ SSL è­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O å…¨å°è‚¡æ¡é›†ä¸­å¿ƒ", layout="wide", page_icon="ğŸ“Š")
st.title("ğŸ“Š D&O æ™ºèƒ½æ ¸ä¿ - å…¨å°è‚¡è‡ªå‹•åŒ–æ¡é›†ä¸­å¿ƒ (å« EPS è‡ªå‹•è£œç®—)")

# è®€å– Supabase è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å– ä¸Šå¸‚/ä¸Šæ«ƒ/èˆˆæ«ƒ ç¸½è¡¨ ---
@st.cache_data(ttl=3600)
def get_all_tw_companies():
    """å¾è­‰äº¤æ‰€æŠ“å–ä¸¦åˆä½µæ¸…å–®"""
    sources = [
        ("ä¸Šå¸‚", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"),
        ("ä¸Šæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"),
        ("èˆˆæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=5")
    ]
    all_dfs = []
    
    progress_text = st.empty()
    try:
        for market_name, url in sources:
            progress_text.text(f"æ­£åœ¨ä¸‹è¼‰ {market_name} æ¸…å–®...")
            response = requests.get(url, verify=False)
            response.encoding = 'cp950'
            dfs = pd.read_html(response.text)
            df = dfs[0]
            
            # è³‡æ–™æ¸…ç†
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].notna()]
            
            # åªè¦è‚¡ç¥¨
            df_stock = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains('ã€€')]
            
            # æ‹†åˆ† ä»£è™Ÿ èˆ‡ åç¨±
            df_stock[['ä»£è™Ÿ', 'åç¨±']] = df_stock['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', expand=True).iloc[:, :2]
            df_stock['å¸‚å ´åˆ¥'] = market_name
            
            # ğŸ”¥ ä¿®æ­£é»ï¼šå°‡ 'ç”¢æ¥­åˆ¥' åŠ å›ç›®æ¨™æ¬„ä½ï¼Œä¸¦åšé˜²å‘†è™•ç†
            target_cols = ['ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥']
            
            # ç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œè‹¥ç„¡å‰‡è£œ "-" (é¿å… KeyError)
            for col in target_cols:
                if col not in df_stock.columns:
                    df_stock[col] = "-"
            
            clean_df = df_stock[target_cols]
            clean_df = clean_df[clean_df['ä»£è™Ÿ'].str.match(r'^\d{4}$')]
            all_dfs.append(clean_df)
            
        progress_text.empty()
        if all_dfs:
            return pd.concat(all_dfs, ignore_index=True)
        return pd.DataFrame()
    except Exception as e:
        st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
        return pd.DataFrame()

# --- 3. è¼”åŠ©å‡½æ•¸ ---
def date_to_roc_quarter(date_obj):
    """å°‡æ—¥æœŸè½‰ç‚ºæ°‘åœ‹å­£åˆ¥ (ä¾‹å¦‚: 114å¹´ Q1)"""
    year_roc = date_obj.year - 1911
    quarter = (date_obj.month - 1) // 3 + 1
    return f"{year_roc}å¹´ Q{quarter}"

def date_to_roc_year(date_obj):
    """å°‡æ—¥æœŸè½‰ç‚ºæ°‘åœ‹å¹´åº¦ (ä¾‹å¦‚: 112å¹´)"""
    year_roc = date_obj.year - 1911
    return f"{year_roc}å¹´"

# --- ğŸ”¥ æ–°å¢åŠŸèƒ½ï¼šSmart EPS è¨ˆç®—å™¨ ---
def get_smart_eps_dict(stock):
    """
    è¨ˆç®— EPS è£œæ´é‚è¼¯ï¼š
    é‡å°æ¯ä¸€å¹´ï¼Œå¦‚æœ Q4 æ˜¯ç©ºçš„ï¼Œç”¨ (å¹´åº¦ç¸½ EPS - å‰ä¸‰å­£ç¸½å’Œ) ç®—å‡ºä¾†ã€‚
    å›å‚³å­—å…¸æ ¼å¼: {'113å¹´ Q4': '0.52', '112å¹´ Q4': '1.23'}
    """
    smart_dict = {}
    try:
        # å–å¾— Basic EPS çš„ Series (è‹¥ç„¡å‰‡å›å‚³ç©º)
        q_eps = stock.quarterly_financials.loc["Basic EPS"] if "Basic EPS" in stock.quarterly_financials.index else pd.Series(dtype=float)
        a_eps = stock.financials.loc["Basic EPS"] if "Basic EPS" in stock.financials.index else pd.Series(dtype=float)
        
        # éæ­·æ¯ä¸€å€‹å¹´åº¦ (ä¾‹å¦‚ 2024, 2023...)
        for year_date in a_eps.index:
            target_year = year_date.year
            year_total = a_eps[year_date]
            
            # å¦‚æœå¹´åº¦æ•¸æ“šæ˜¯ç©ºçš„ï¼Œå°±è·³é
            if pd.isna(year_total):
                continue

            # æŠ“å–è©²å¹´åº¦ Q1, Q2, Q3 (å®¹éŒ¯ get)
            q1 = q_eps.get(pd.Timestamp(f"{target_year}-03-31"), 0)
            q2 = q_eps.get(pd.Timestamp(f"{target_year}-06-30"), 0)
            q3 = q_eps.get(pd.Timestamp(f"{target_year}-09-30"), 0)
            
            # æª¢æŸ¥åŸå§‹ Q4 (é€šå¸¸æ˜¯ 12-31)
            q4_date = pd.Timestamp(f"{target_year}-12-31")
            q4_raw = q_eps.get(q4_date)
            
            final_q4_val = 0
            is_calculated = False

            # å¦‚æœ Q4 æ˜¯ NaN æˆ– 0ï¼Œä¸”å¹´åº¦æœ‰å€¼ï¼Œå°±å•Ÿå‹•è£œç®—
            if pd.isna(q4_raw) or q4_raw == 0:
                # è£œç®—å…¬å¼
                calculated_q4 = year_total - (q1 + q2 + q3)
                final_q4_val = calculated_q4
                is_calculated = True
            else:
                final_q4_val = q4_raw
            
            # å°‡çµæœå­˜å…¥å­—å…¸ï¼ŒKey è¦å°æ‡‰ date_to_roc_quarter çš„æ ¼å¼
            # ä¾‹å¦‚ 2024-12-31 -> 113å¹´ Q4
            roc_key = date_to_roc_quarter(q4_date)
            
            # è½‰æˆå­—ä¸² (ä¿ç•™å…©ä½å°æ•¸)
            smart_dict[roc_key] = f"{final_q4_val:.2f}"
            
            # (é¸ç”¨) ç‚ºäº†ä¿éšªï¼Œä¹Ÿå¯æŠŠ Q1-Q3 å­˜é€²å»ï¼Œç¢ºä¿æ•¸æ“šä¸€è‡´
            smart_dict[date_to_roc_quarter(pd.Timestamp(f"{target_year}-03-31"))] = f"{q1:.2f}"
            smart_dict[date_to_roc_quarter(pd.Timestamp(f"{target_year}-06-30"))] = f"{q2:.2f}"
            smart_dict[date_to_roc_quarter(pd.Timestamp(f"{target_year}-09-30"))] = f"{q3:.2f}"

    except Exception as e:
        # é‹ç®—å¤±æ•—ä¸å¡æµç¨‹ï¼Œå›å‚³ç©ºå­—å…¸
        print(f"Smart EPS Error: {e}")
        return {}
    
    return smart_dict

# --- 4. æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ (å«å¹´åº¦+å­£åº¦+EPSè£œç®—) ---
def fetch_and_upload_data(stock_code, stock_name_tw=None, market_type="ä¸Šå¸‚"):
    """
    æŠ“å–å­£åº¦èˆ‡å¹´åº¦å ±è¡¨ä¸¦åˆä½µ
    """
    suffix = ".TWO" if market_type in ["ä¸Šæ«ƒ", "èˆˆæ«ƒ"] else ".TW"
    ticker_symbol = f"{stock_code}{suffix}"
    
    stock = yf.Ticker(ticker_symbol)
    
    try:
        # ğŸ”¥ æ­¥é©Ÿ 0: å…ˆç®—å‡º Smart EPS å­—å…¸ (è£œæ´ç”¨)
        smart_eps_lookup = get_smart_eps_dict(stock)

        # ==========================================
        # æ­¥é©Ÿ A: æŠ“å–ã€Œå­£åº¦ã€å ±è¡¨ (Quarterly)
        # ==========================================
        q_bs = stock.quarterly_balance_sheet
        q_is = stock.quarterly_financials
        q_cf = stock.quarterly_cashflow 
        
        if q_bs.empty or q_is.empty:
            return False, f"ç„¡è²¡å‹™æ•¸æ“š ({ticker_symbol})"

        # åˆä½µå­£åº¦å ±è¡¨
        df_q = pd.concat([q_is.T, q_bs.T, q_cf.T], axis=1)
        df_q = df_q.loc[:, ~df_q.columns.duplicated()]
        df_q.index = pd.to_datetime(df_q.index)
        # åªå–è¿‘ 12 å­£
        df_q_sorted = df_q.sort_index(ascending=False).head(12)

        # ==========================================
        # æ­¥é©Ÿ B: æŠ“å–ã€Œå¹´åº¦ã€å ±è¡¨ (Annual)
        # ==========================================
        a_bs = stock.balance_sheet
        a_is = stock.financials
        a_cf = stock.cashflow

        df_a_sorted = pd.DataFrame()
        if not a_is.empty:
            df_a = pd.concat([a_is.T, a_bs.T, a_cf.T], axis=1)
            df_a = df_a.loc[:, ~df_a.columns.duplicated()]
            df_a.index = pd.to_datetime(df_a.index)
            # å–è¿‘ 5 å¹´
            df_a_sorted = df_a.sort_index(ascending=False).head(5)

        # ==========================================
        # æ­¥é©Ÿ C: æ•´åˆæ¬„ä½èˆ‡æ•¸æ“š
        # ==========================================
        mapping = {
            "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥", "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Total Assets": "ç¸½è³‡ç”¢",
            "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ", "Total Liabilities": "ç¸½è² å‚µ",
            "Current Assets": "æµå‹•è³‡ç”¢", "Current Liabilities": "æµå‹•è² å‚µ",
            "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
            "Total Cash From Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ", 
            "Cash Flow From Continuing Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        }
        
        target_items = [
            "ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", 
            "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", 
            "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        ]
        
        formatted_data = []

        for target_name in target_items:
            row_dict = {"é …ç›®": target_name}
            
            # --- 1. è™•ç†å­£åº¦æ•¸æ“š (Quarterly) ---
            for date_idx in df_q_sorted.index:
                key_name = date_to_roc_quarter(date_idx) # æ ¼å¼ï¼š114å¹´ Q1
                
                # ğŸ”¥ é—œéµä¿®æ”¹ï¼šå¦‚æœæ˜¯ EPS ä¸”å­˜åœ¨æ–¼ Smart Dictionary ä¸­ï¼Œç›´æ¥ç”¨ç®—å¥½çš„å€¼
                if target_name == "æ¯è‚¡ç›ˆé¤˜(EPS)" and key_name in smart_eps_lookup:
                    row_dict[key_name] = smart_eps_lookup[key_name]
                else:
                    # å¦å‰‡èµ°åŸæœ¬çš„æŠ“å–é‚è¼¯
                    val = extract_value(df_q_sorted, date_idx, target_name, mapping)
                    row_dict[key_name] = val

            # --- 2. è™•ç†å¹´åº¦æ•¸æ“š (Annual) ---
            if not df_a_sorted.empty:
                for date_idx in df_a_sorted.index:
                    key_name = date_to_roc_year(date_idx) # æ ¼å¼ï¼š112å¹´
                    val = extract_value(df_a_sorted, date_idx, target_name, mapping)
                    row_dict[key_name] = val
            
            formatted_data.append(row_dict)

        # ä¸Šå‚³ Supabase
        final_name = stock_name_tw if stock_name_tw else stock.info.get('longName', stock_code)
        payload = {
            "code": stock_code,
            "name": final_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        supabase.table("underwriting_cache").upsert(payload).execute()
        return True, f"æˆåŠŸåŒæ­¥: {final_name} ({suffix})"

    except Exception as e:
        return False, str(e)

# æ•¸å€¼æå–è¼”åŠ©å‡½å¼
def extract_value(df, date_idx, target_name, mapping):
    if target_name == "è² å‚µæ¯”":
        try:
            liab = df.loc[date_idx].get("Total Liabilities Net Minority Interest") or df.loc[date_idx].get("Total Liabilities")
            assets = df.loc[date_idx].get("Total Assets")
            if liab and assets:
                return f"{(liab / assets) * 100:.2f}%"
        except: pass
        return "-"
    else:
        found_val = None
        for eng_col, ch_col in mapping.items():
            if ch_col == target_name and eng_col in df.columns:
                val = df.loc[date_idx, eng_col]
                if pd.notna(val):
                    found_val = val
                    break
        
        if found_val is not None:
            if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                try: return f"{int(found_val / 1000):,}"
                except: return "-"
            else:
                return f"{found_val:.2f}"
    return "-"

# --- 5. UI ä»‹é¢ ---
with st.sidebar:
    st.header("ğŸ’¾ è³‡æ–™åº«ç‹€æ…‹")
    if st.button("ğŸ”„ åˆ·æ–°è³‡æ–™åº«åˆ—è¡¨"):
        try:
            res = supabase.table("underwriting_cache").select("code, name, updated_at", count="exact").execute()
            st.metric("å·²å»ºæª”å…¬å¸æ•¸", res.count)
            if res.data:
                df_db = pd.DataFrame(res.data)
                df_db['updated_at'] = pd.to_datetime(df_db['updated_at']).dt.strftime('%Y-%m-%d %H:%M')
                st.dataframe(df_db, hide_index=True)
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—: {e}")

tab1, tab2 = st.tabs(["ğŸš€ å…¨å¸‚å ´æ‰¹é‡æ¡é›†", "ğŸ” æ‰‹å‹•æŸ¥è©¢"])

with tab1:
    st.markdown("### ğŸ¢ ä¸Šå¸‚ / ä¸Šæ«ƒ / èˆˆæ«ƒ ç¸½è¡¨")
    col_src1, col_src2 = st.columns(2)
    with col_src1:
        if st.button("ğŸŒ ä¸‹è¼‰å…¨å¸‚å ´æœ€æ–°æ¸…å–®"):
            with st.spinner("ä¸‹è¼‰ä¸­ (å«ä¸Šå¸‚/æ«ƒ/èˆˆæ«ƒ)..."):
                df = get_all_tw_companies()
                if not df.empty:
                    st.session_state.twse_df = df
                    st.success(f"æˆåŠŸè¼‰å…¥ {len(df)} å®¶å…¬å¸")
                else:
                    st.error("æ¸…å–®è¼‰å…¥å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦")

    with col_src2:
        if st.button("ğŸ’¾ è¼‰å…¥ Supabase æ¸…å–®"):
            with st.spinner("è®€å–è³‡æ–™åº«..."):
                try:
                    res = supabase.table("underwriting_cache").select("code, name, updated_at").execute()
                    if res.data:
                        df_db = pd.DataFrame(res.data)
                        df_db = df_db.rename(columns={"code": "ä»£è™Ÿ", "name": "åç¨±"})
                        df_db['ç”¢æ¥­åˆ¥'] = "å·²å»ºæª”"
                        df_db['å¸‚å ´åˆ¥'] = "Supabase"
                        df_db['ä¸Šå¸‚æ—¥'] = df_db['updated_at'].apply(lambda x: str(x)[:10])
                        st.session_state.twse_df = df_db
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(df_db)} ç­†")
                except Exception as e: st.error(f"è®€å–å¤±æ•—: {e}")

    if 'twse_df' in st.session_state and st.session_state.twse_df is not None:
        df = st.session_state.twse_df
        st.markdown("---")
        
        # ç¯©é¸å™¨ UI
        c1, c2, c3 = st.columns(3)
        with c1: 
            all_mkts = ["å…¨éƒ¨"] + list(df['å¸‚å ´åˆ¥'].unique())
            mkt = st.selectbox("å¸‚å ´", all_mkts)
            
        with c2: 
            # é˜²å‘†ï¼šç¢ºä¿æœ‰ç”¢æ¥­åˆ¥æ¬„ä½
            if 'ç”¢æ¥­åˆ¥' in df.columns:
                all_inds = ["å…¨éƒ¨"] + list(df['ç”¢æ¥­åˆ¥'].unique())
            else:
                all_inds = ["å…¨éƒ¨"]
            ind = st.selectbox("ç”¢æ¥­", all_inds)
            
        with c3: txt = st.text_input("æœå°‹ (ä»£è™Ÿ/åç¨±)", "")
        
        # ç¯©é¸é‚è¼¯
        f_df = df.copy()
        if mkt != "å…¨éƒ¨": f_df = f_df[f_df['å¸‚å ´åˆ¥'] == mkt]
        if ind != "å…¨éƒ¨" and 'ç”¢æ¥­åˆ¥' in f_df.columns: f_df = f_df[f_df['ç”¢æ¥­åˆ¥'] == ind]
        if txt: f_df = f_df[f_df['ä»£è™Ÿ'].str.contains(txt) | f_df['åç¨±'].str.contains(txt)]
        
        st.write(f"é¡¯ç¤º {len(f_df)} ç­†è³‡æ–™:")
        
        # å…¨é¸é‚è¼¯
        if 'editor_key' not in st.session_state: st.session_state.editor_key = 0
        if 'def_sel' not in st.session_state: st.session_state.def_sel = False
        
        cb1, cb2, _ = st.columns([1,1,6])
        if cb1.button("âœ… å…¨é¸"): 
            st.session_state.def_sel = True
            st.session_state.editor_key += 1
            st.rerun()
        if cb2.button("âŒ å–æ¶ˆ"): 
            st.session_state.def_sel = False
            st.session_state.editor_key += 1
            st.rerun()
            
        f_df['é¸å–'] = st.session_state.def_sel
        
        # ç¢ºä¿é¡¯ç¤ºæ¬„ä½å­˜åœ¨
        display_cols = ['é¸å–', 'ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥']
        valid_cols = [c for c in display_cols if c in f_df.columns]
        
        edited_df = st.data_editor(
            f_df[valid_cols], hide_index=True,
            column_config={"é¸å–": st.column_config.CheckboxColumn(required=True)},
            disabled=[c for c in valid_cols if c != 'é¸å–'],
            height=400, key=f"editor_{st.session_state.editor_key}"
        )
        
        sel_rows = edited_df[edited_df['é¸å–'] == True]
        if not sel_rows.empty:
            st.warning(f"âš ï¸ å³å°‡æ›´æ–° {len(sel_rows)} å®¶å…¬å¸")
            if st.button("ğŸš€ åŸ·è¡Œæ‰¹é‡æ›´æ–°", type="primary"):
                p_bar = st.progress(0)
                status = st.empty()
                total = len(sel_rows)
                for i, row in enumerate(sel_rows.itertuples()):
                    # å®‰å…¨å–å¾—å±¬æ€§ (é¿å… AttributeError)
                    code = getattr(row, 'ä»£è™Ÿ') if hasattr(row, 'ä»£è™Ÿ') else row._2 # å‚™ç”¨
                    name = getattr(row, 'åç¨±') if hasattr(row, 'åç¨±') else row._3
                    mkt_type = getattr(row, 'å¸‚å ´åˆ¥', 'ä¸Šå¸‚') if hasattr(row, 'å¸‚å ´åˆ¥') else "ä¸Šå¸‚"
                    
                    status.text(f"è™•ç†ä¸­ ({i+1}/{total}): {code} {name}")
                    fetch_and_upload_data(code, name, mkt_type)
                    p_bar.progress((i+1)/total)
                    time.sleep(1) # é¿å…å°é–
                status.success("ğŸ‰ æ‰¹é‡æ›´æ–°å®Œæˆï¼")

with tab2:
    st.markdown("### ğŸ“ æ‰‹å‹•å–®ç­†æŸ¥è©¢")
    s_in = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ", value="2330", help="ä¾‹å¦‚ 2330, 8069")
    m_type = st.radio("é¸æ“‡å¸‚å ´", ["ä¸Šå¸‚", "ä¸Šæ«ƒ/èˆˆæ«ƒ"], horizontal=True)
    
    if st.button("åŸ·è¡Œå–®ç­†æ¡é›†", type="primary"):
        if s_in:
            real_mkt = "ä¸Šå¸‚" if "ä¸Šå¸‚" in m_type else "ä¸Šæ«ƒ"
            with st.spinner(f"æ­£åœ¨æŠ“å– {s_in} ({real_mkt})..."):
                suc, msg = fetch_and_upload_data(s_in, market_type=real_mkt)
                if suc: st.success(msg)
                else: st.error(msg)
