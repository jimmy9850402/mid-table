import streamlit as st
import pandas as pd
import yfinance as yf
from supabase import create_client
import os
from datetime import datetime
import time
import requests
import ssl
from requests.packages.urllib3.exceptions import InsecureRequestWarning

# å¿½ç•¥ SSL è­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="å¯Œé‚¦ D&O å…¨å°è‚¡æ¡é›†ä¸­å¿ƒ", layout="wide", page_icon="ğŸ“Š")
st.title("ğŸ“Š D&O æ™ºèƒ½æ ¸ä¿ - å…¨å°è‚¡è‡ªå‹•åŒ–æ¡é›†ä¸­å¿ƒ (ä¸Šå¸‚/ä¸Šæ«ƒ/èˆˆæ«ƒ)")

# è®€å– Supabase è¨­å®š
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    st.error("âš ï¸ è«‹è¨­å®š Supabase URL èˆ‡ Key")
    st.stop()

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæŠ“å– ä¸Šå¸‚/ä¸Šæ«ƒ/èˆˆæ«ƒ ç¸½è¡¨ ---
@st.cache_data(ttl=3600)
def get_all_tw_companies():
    """å¾è­‰äº¤æ‰€æŠ“å– ä¸Šå¸‚ã€ä¸Šæ«ƒã€èˆˆæ«ƒ æ¸…å–®ä¸¦åˆä½µ"""
    
    # å®šç¾©ä¾†æº (åç¨±, URL, å¸‚å ´ä»£ç¢¼)
    sources = [
        ("ä¸Šå¸‚", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"), # ä¸Šå¸‚
        ("ä¸Šæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"), # ä¸Šæ«ƒ
        ("èˆˆæ«ƒ", "https://isin.twse.com.tw/isin/C_public.jsp?strMode=5")  # èˆˆæ«ƒ
    ]
    
    all_dfs = []
    
    progress_text = st.empty()
    
    try:
        for market_name, url in sources:
            progress_text.text(f"æ­£åœ¨ä¸‹è¼‰ {market_name} æ¸…å–®...")
            
            # ä½¿ç”¨ requests ç•¥é SSL
            response = requests.get(url, verify=False)
            response.encoding = 'cp950' 
            
            dfs = pd.read_html(response.text)
            df = dfs[0]
            
            # è³‡æ–™æ¸…ç†
            df.columns = df.iloc[0]
            df = df.iloc[1:]
            df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].notna()]
            
            # åªè¦è‚¡ç¥¨
            df_stock = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains('ã€€')]
            
            # æ‹†åˆ† ä»£è™Ÿ èˆ‡ åç¨±
            df_stock[['ä»£è™Ÿ', 'åç¨±']] = df_stock['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split('ã€€', expand=True).iloc[:, :2]
            
            # æ¨™è¨˜å¸‚å ´åˆ¥ (é‡è¦ï¼ç”¨ä¾†åˆ¤æ–· .TW æˆ– .TWO)
            df_stock['å¸‚å ´åˆ¥'] = market_name
            
            # ä¿ç•™æ¬„ä½
            # æ³¨æ„ï¼šèˆˆæ«ƒçš„è¡¨æ ¼æ¬„ä½å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œé€™è£¡å–äº¤é›†æˆ–æ ¸å¿ƒæ¬„ä½
            target_cols = ['ä»£è™Ÿ', 'åç¨±', 'ç”¢æ¥­åˆ¥', 'å¸‚å ´åˆ¥', 'ä¸Šå¸‚æ—¥'] # ä¸Šå¸‚æ—¥å¯èƒ½åœ¨èˆˆæ«ƒå«åˆ¥çš„åå­—ï¼Œå…ˆå˜—è©¦é€šç”¨
            
            # ç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œè‹¥ç„¡å‰‡è£œç©ºå€¼ (é¿å…èˆˆæ«ƒå ±éŒ¯)
            for col in target_cols:
                if col not in df_stock.columns:
                    df_stock[col] = "-"
            
            clean_df = df_stock[target_cols]
            
            # éæ¿¾ä»£è™Ÿï¼šåªç•™ 4 ç¢¼æ•¸å­—
            clean_df = clean_df[clean_df['ä»£è™Ÿ'].str.match(r'^\d{4}$')]
            
            all_dfs.append(clean_df)
            
        progress_text.empty()
        
        # åˆä½µæ‰€æœ‰ DataFrame
        if all_dfs:
            final_df = pd.concat(all_dfs, ignore_index=True)
            return final_df
        else:
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
        return pd.DataFrame()

# --- 3. è¼”åŠ©å‡½æ•¸ ---
def date_to_roc_quarter(date_obj):
    year_roc = date_obj.year - 1911
    quarter = (date_obj.month - 1) // 3 + 1
    return f"{year_roc}å¹´ Q{quarter}"

# --- 4. æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ (æ”¯æ´ .TWO) ---
def fetch_and_upload_data(stock_code, stock_name_tw=None, market_type="ä¸Šå¸‚"):
    """
    market_type: "ä¸Šå¸‚", "ä¸Šæ«ƒ", "èˆˆæ«ƒ" (ç”¨ä¾†æ±ºå®šå¾Œç¶´)
    """
    
    # ğŸ”¥ é—œéµåˆ¤æ–·ï¼šä¸Šå¸‚ç”¨ .TWï¼Œä¸Šæ«ƒ/èˆˆæ«ƒç”¨ .TWO
    suffix = ".TW"
    if market_type in ["ä¸Šæ«ƒ", "èˆˆæ«ƒ"]:
        suffix = ".TWO"
    
    ticker_symbol = f"{stock_code}{suffix}"
    
    # èˆˆæ«ƒå‚™ç”¨æ–¹æ¡ˆï¼šæœ‰æ™‚å€™ Yahoo Finance å°èˆˆæ«ƒæ”¯æ´ä¸ä½³ï¼Œè‹¥ .TWO å¤±æ•—å¯å˜—è©¦ .TWï¼Œä½†é€šå¸¸æ˜¯ .TWO
    
    stock = yf.Ticker(ticker_symbol)
    
    try:
        bs = stock.quarterly_balance_sheet
        is_ = stock.quarterly_financials
        cf = stock.quarterly_cashflow 
        
        if bs.empty or is_.empty:
            return False, f"ç„¡è²¡å‹™æ•¸æ“š ({ticker_symbol})"

        # åˆä½µå ±è¡¨
        df_merged = pd.concat([is_.T, bs.T, cf.T], axis=1)
        df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]
        df_merged.index = pd.to_datetime(df_merged.index)
        
        # æŠ“è¿‘ 12 å­£
        df_sorted = df_merged.sort_index(ascending=False).head(12)
        
        # Mapping
        mapping = {
            "Total Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Operating Revenue": "ç‡Ÿæ¥­æ”¶å…¥",
            "Total Assets": "ç¸½è³‡ç”¢",
            "Total Liabilities Net Minority Interest": "ç¸½è² å‚µ",
            "Total Liabilities": "ç¸½è² å‚µ",
            "Current Assets": "æµå‹•è³‡ç”¢",
            "Current Liabilities": "æµå‹•è² å‚µ",
            "Basic EPS": "æ¯è‚¡ç›ˆé¤˜(EPS)",
            "Operating Cash Flow": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ",
            "Total Cash From Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ",
            "Cash Flow From Continuing Operating Activities": "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        }
        
        target_items = [
            "ç‡Ÿæ¥­æ”¶å…¥", "ç¸½è³‡ç”¢", "è² å‚µæ¯”", 
            "æµå‹•è³‡ç”¢", "æµå‹•è² å‚µ", "æ¯è‚¡ç›ˆé¤˜(EPS)", 
            "ç‡Ÿæ¥­æ´»å‹•æ·¨ç¾é‡‘æµ"
        ]
        
        formatted_data = []

        for target_name in target_items:
            row_dict = {"é …ç›®": target_name}
            for date_idx in df_sorted.index:
                key_name = date_to_roc_quarter(date_idx)
                
                if target_name == "è² å‚µæ¯”":
                    try:
                        liab = df_sorted.loc[date_idx].get("Total Liabilities Net Minority Interest") or df_sorted.loc[date_idx].get("Total Liabilities")
                        assets = df_sorted.loc[date_idx].get("Total Assets")
                        if liab and assets:
                            val = (liab / assets) * 100
                            row_dict[key_name] = f"{val:.2f}%"
                        else:
                            row_dict[key_name] = "-"
                    except:
                        row_dict[key_name] = "-"
                else:
                    found_val = None
                    for eng_col, ch_col in mapping.items():
                        if ch_col == target_name:
                            if eng_col in df_sorted.columns:
                                val = df_sorted.loc[date_idx, eng_col]
                                if pd.notna(val):
                                    found_val = val
                                    break
                    
                    if found_val is not None:
                        if target_name != "æ¯è‚¡ç›ˆé¤˜(EPS)":
                            try:
                                row_dict[key_name] = f"{int(found_val / 1000):,}"
                            except:
                                row_dict[key_name] = "-"
                        else:
                            row_dict[key_name] = f"{found_val:.2f}"
                    else:
                        row_dict[key_name] = "-"
            
            formatted_data.append(row_dict)

        final_name = stock_name_tw if stock_name_tw else stock.info.get('longName', stock_code)

        payload = {
            "code": stock_code,
            "name": final_name,
            "financial_data": formatted_data,
            "updated_at": datetime.now().isoformat()
        }
        
        supabase.table("underwriting_cache").upsert(payload).execute()
        return True, f"æˆåŠŸåŒæ­¥: {final_name} ({suffix})"

    except Exception as e:
        return False, str(e)

# --- 5. UI ä»‹é¢ ---
with st.sidebar:
    st.header("ğŸ’¾ è³‡æ–™åº«ç‹€æ…‹")
    if st.button("ğŸ”„ åˆ·æ–°è³‡æ–™åº«åˆ—è¡¨"):
        try:
            res = supabase.table("underwriting_cache").select("code, name, updated_at", count="exact").execute()
            st.metric("å·²å»ºæª”å…¬å¸æ•¸", res.count)
            if res.data:
                df_db = pd.DataFrame(res.data)
                df_db['updated_at'] = pd.to_datetime(df_db['updated_at']).dt.strftime('%Y-%m-%d %H:%M')
                st.dataframe(df_db, hide_index=True)
        except Exception as e:
            st.error(f"é€£ç·šå¤±æ•—: {e}")

tab1, tab2 = st.tabs(["ğŸš€ å…¨å¸‚å ´æ‰¹é‡æ¡é›† (ä¸Šå¸‚/æ«ƒ/èˆˆ)", "ğŸ” æ‰‹å‹•æŸ¥è©¢"])

# --- Tab 1: å…¨å¸‚å ´åˆ—è¡¨ ---
with tab1:
    st.markdown("### ğŸ¢ ä¸Šå¸‚ / ä¸Šæ«ƒ / èˆˆæ«ƒ ç¸½è¡¨")
    
    col_src1, col_src2 = st.columns(2)
    
    # ä¾†æº A: è­‰äº¤æ‰€/æ«ƒè²·ä¸­å¿ƒ (æ•´åˆç‰ˆ)
    with col_src1:
        if st.button("ğŸŒ ä¸‹è¼‰å…¨å¸‚å ´æœ€æ–°æ¸…å–® (ä¸Šå¸‚+ä¸Šæ«ƒ+èˆˆæ«ƒ)"):
            with st.spinner("æ­£åœ¨é€£ç·šè­‰äº¤æ‰€èˆ‡æ«ƒè²·ä¸­å¿ƒ..."):
                df = get_all_tw_companies()
                if not df.empty:
                    st.session_state.twse_df = df
                    st.success(f"æˆåŠŸè¼‰å…¥ {len(df)} å®¶å…¬å¸ï¼(å«èˆˆæ«ƒ)")
                else:
                    st.error("æ¸…å–®ä¸‹è¼‰å¤±æ•—")

    # ä¾†æº B: Supabase
    with col_src2:
        if st.button("ğŸ’¾ è¼‰å…¥ Supabase ç¾æœ‰æ¸…å–®"):
            with st.spinner("è®€å–ä¸­..."):
                try:
                    res = supabase.table("underwriting_cache").select("code, name, updated_at").execute()
                    if res.data:
                        df_db = pd.DataFrame(res.data)
                        df_db = df_db.rename(columns={"code": "ä»£è™Ÿ", "name": "åç¨±"})
                        df_db['ç”¢æ¥­åˆ¥'] = "å·²å»ºæª”"
                        df_db['å¸‚å ´åˆ¥'] = "Supabase" # æ¨™è¨˜ä¾†æº
                        df_db['ä¸Šå¸‚æ—¥'] = df_db['updated_at'].apply(lambda x: str(x)[:10])
                        st.session_state.twse_df = df_db
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(df_db)} ç­†ï¼")
                except Exception as e:
                    st.error(f"è®€å–å¤±æ•—: {e}")

    # é¡¯ç¤ºå€
    if 'twse_df' in st.session_state and st.session_state.twse_df is not None:
        df = st.session_state.twse_df
        
        st.markdown("---")
        # ç¯©é¸å™¨ (å¢åŠ å¸‚å ´åˆ¥)
        col_f1, col_f2, col_f3 = st.columns(3)
        
        with col_f1:
            all_markets = ["å…¨éƒ¨"] + list(df['å¸‚å ´åˆ¥'].unique())
            sel_market = st.selectbox("ğŸ“Š ç¯©é¸å¸‚å ´", all_markets)
            
        with col_f2:
            all_inds = ["å…¨éƒ¨"] + list(df['ç”¢æ¥­åˆ¥'].unique())
            sel_ind = st.selectbox("ğŸ“‚ ç¯©é¸ç”¢æ¥­", all_inds)
            
        with col_f3:
            search_txt = st.text_input("ğŸ” æœå°‹ä»£è™Ÿ/åç¨±", "")

        # å¥—ç”¨ç¯©é¸
        f_df = df.copy()
        if sel_market != "å…¨éƒ¨":
            f_df = f_df[f_df['å¸‚å ´åˆ¥'] == sel_market]
        if sel_ind != "å…¨éƒ¨":
            f_df = f_df[f_df['ç”¢æ¥­åˆ¥'] == sel_ind]
        if search_txt:
            f_df = f_df[f_df['ä»£è™Ÿ'].str.contains(search_txt) | f_df['åç¨±'].str.contains(search_txt)]

        st.write(f"é¡¯ç¤º {len(f_df)} ç­†è³‡æ–™:")
        
        # å…¨é¸åŠŸèƒ½
        c_btn1, c_btn2, _ = st.columns([1, 1, 6])
        if 'editor_key' not in st.session_state: st.session_state.editor_key = 0
        if 'def_sel' not in st.session_state: st.session_state.def_sel = False
        
        if c_btn1.button("âœ… å…¨é¸"):
            st.session_state.def_sel = True
            st.session_state.editor_key += 1
            st.rerun()
        if c_btn2.button("âŒ å–æ¶ˆå…¨é¸"):
            st.session_state.def_sel = False
            st.session_state.editor_key += 1
            st.rerun()

        f_df['é¸å–'] = st.session_state.def_sel
        cols = ['é¸å–', 'ä»£è™Ÿ', 'åç¨±', 'å¸‚å ´åˆ¥', 'ç”¢æ¥­åˆ¥', 'ä¸Šå¸‚æ—¥']
        
        # ç¢ºä¿åªé¡¯ç¤ºå­˜åœ¨çš„æ¬„ä½
        valid_cols = [c for c in cols if c in f_df.columns]
        
        edited_df = st.data_editor(
            f_df[valid_cols],
            hide_index=True,
            column_config={"é¸å–": st.column_config.CheckboxColumn(required=True)},
            disabled=[c for c in valid_cols if c != 'é¸å–'],
            height=400,
            key=f"editor_{st.session_state.editor_key}"
        )

        # åŸ·è¡Œæ‰¹é‡
        sel_rows = edited_df[edited_df['é¸å–'] == True]
        if not sel_rows.empty:
            st.warning(f"âš ï¸ å³å°‡æ›´æ–° {len(sel_rows)} å®¶å…¬å¸ ({sel_rows['å¸‚å ´åˆ¥'].unique()})")
            if st.button("ğŸš€ é–‹å§‹æ‰¹é‡æ›´æ–°"):
                prog_bar = st.progress(0)
                status = st.empty()
                logs = st.expander("åŸ·è¡Œç´€éŒ„", expanded=True)
                
                total = len(sel_rows)
                ok_cnt = 0
                
                for i, row in enumerate(sel_rows.itertuples()):
                    # å®‰å…¨ç²å–æ¬„ä½ (å› ç‚º index æœƒè®Š)
                    # getattr(row, 'ä»£è™Ÿ') æ˜¯æ¯”è¼ƒå®‰å…¨çš„åšæ³•
                    code = getattr(row, 'ä»£è™Ÿ')
                    name = getattr(row, 'åç¨±')
                    mkt = getattr(row, 'å¸‚å ´åˆ¥', 'ä¸Šå¸‚') # é è¨­ä¸Šå¸‚
                    
                    status.text(f"({i+1}/{total}) è™•ç†ä¸­: {code} {name} [{mkt}]...")
                    
                    # å‚³å…¥ market_type ä»¥æ±ºå®šå¾Œç¶´
                    suc, msg = fetch_and_upload_data(code, name, market_type=mkt)
                    
                    if suc:
                        ok_cnt += 1
                        logs.write(f"âœ… {code}: {msg}")
                    else:
                        logs.write(f"âŒ {code}: {msg}")
                    
                    prog_bar.progress((i+1)/total)
                    time.sleep(1.0)
                
                status.success(f"å®Œæˆï¼æˆåŠŸ {ok_cnt}/{total}")

# --- Tab 2: å–®ç­†æ¨¡å¼ ---
with tab2:
    st.markdown("### ğŸ“ æ‰‹å‹•è¼¸å…¥")
    s_in = st.text_input("è¼¸å…¥ä»£è™Ÿ", value="8069", help="ä¾‹å¦‚ 8069 (å…ƒå¤ª - ä¸Šæ«ƒ)")
    # æ‰‹å‹•é¸æ“‡å¸‚å ´ï¼Œä»¥å…ä½¿ç”¨è€…è¼¸å…¥èˆˆæ«ƒä»£è™Ÿå»æŸ¥ä¸åˆ°
    m_type = st.radio("é¸æ“‡å¸‚å ´åˆ¥ (å½±éŸ¿æŸ¥è©¢ä»£ç¢¼)", ["ä¸Šå¸‚ (.TW)", "ä¸Šæ«ƒ/èˆˆæ«ƒ (.TWO)"], horizontal=True)
    
    if st.button("åŸ·è¡Œå–®ç­†æ¡é›†", type="primary"):
        if s_in:
            real_mkt = "ä¸Šå¸‚" if "ä¸Šå¸‚" in m_type else "ä¸Šæ«ƒ"
            with st.spinner(f"æ­£åœ¨æŠ“å– {s_in} ({real_mkt})..."):
                suc, msg = fetch_and_upload_data(s_in, market_type=real_mkt)
                if suc: st.success(msg)
                else: st.error(msg)
